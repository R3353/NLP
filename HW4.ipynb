{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZkSNhoPtuDC"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucbnlp24/hws4nlp24/blob/main/HW4/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb4Yr8KhRhbe"
      },
      "source": [
        "# Homework 4: Large Language Models & Prompting\n",
        "\n",
        "### Due Date: March 8th, 2024 (11:59pm)\n",
        "\n",
        "## Total Points: 100 points\n",
        "- *Warning*: Start this assignment early as it is dependent on the OpenAI API!\n",
        "- **Overview**: In this assignment, we will examine some of the latest language models you may be familiar with like GPT-3. We'll cover:\n",
        "\n",
        "  - Zero-shot prompting\n",
        "  - Prompt engineering\n",
        "  - Few-shot prompting\n",
        "  - Prompting instruction-tuned models\n",
        "  - Chain-of-Thought Reasoning prompting\n",
        "\n",
        "- **OpenAI Account Setup**: You will need an OpenAI account and API key, you can [sign up here](https://platform.openai.com/signup?launch) (click on `API`) and learn [how to make an API key here](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key). The OpenAI API is paid, however,  this homework will stay well under the free $5 credit given to each account. Be careful not to exhaust your free OpenAI credits while testing, you can check [on this page here](https://platform.openai.com/account/usage). To avoid exhausting your credits quickly, avoid running cells over and over again after you've completed an exercise.\n",
        "\n",
        "- **Grading**: To complete the homework assignment, you should implement anything marked with `#TODO`\n",
        "  - **NOTE #1**: For this assignment you will be creating your own unit tests for the prompts you generate. For each 'Code' section below you are required to write **3 unit tests** per prompt and submit the prompt, unit test, and output (more details in Submissions section) in the report.\n",
        "  - **NOTE #2**: A boilerplate unit test function is provided below in the setup section, feel free to modify or come up with your own as long as you include the **expected** answer and the **response** from the OpenAI API in the cell output and report.\n",
        "  - **NOTE #3**: Points will be deducted if you go over the word limit for questions with a word limit.\n",
        "  - **NOTE #4**: Have fun with this homework! It's meant to be more exploratory and for you to gain exposure to current LLM trends.\n",
        "\n",
        "- **Deliverables:** This assignment has several deliverables:\n",
        "  - Code (this notebook) *(Manually Graded)*\n",
        "    - Section 1: 1.1, 1.2, 1.3, 1.4, 1.5, 1.6\n",
        "    - Section 3: 3.1, 3.2\n",
        "    - Section 4: 4.1, 4.2\n",
        "    - Section 5: 5.1, 5.2\n",
        "  - Write Up (report.pdf) *(Manually Graded)*\n",
        "    - All Sections\n",
        "\n",
        "\n",
        "## Recommended Readings\n",
        "- [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf). Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, ...others. ArXiV 2020.\n",
        "- [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf). Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig. ACM Computing Surveys 2021.\n",
        "- [Best practices for prompt engineering with OpenAI API](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api). Jessica Shieh. OpenAI 2023.\n",
        "- [Training language models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155.pdf). Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, ...others. ArXiV 2020.\n",
        "- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf). Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, Denny Zhou. NeurIPS 2022.\n",
        "\n",
        "## To get started, **make a copy** of this colab notebook into your google drive!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHrdyiQdBt2K"
      },
      "source": [
        "## Setup: Dataset / Packages\n",
        "- **Run the following cells and enter your OpenAI API Key!**\n",
        "- The models we are using are not the best models OpenAI has to offer (for cost reasons), therefore, the output you get from prompting ChatGPT for example may not match the output from the API.\n",
        "- We will be using `babbage-002` and `gpt-3.5-turbo-instruct` for this assignment\n",
        "  - Babbage: can understand and generate natural language but can't follow instructions\n",
        "  - GPT 3.5 Turbo Instruct: can understand and generate natural language as well as follow explicit instructions (more on this in section 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNBeJLVcSusU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install openai datasets\n",
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from time import sleep\n",
        "from datasets import load_dataset\n",
        "\n",
        "IMDB_DATASET = load_dataset(\"imdb\", split='train').shuffle(42)[0:50]\n",
        "IMDB_DATASET_X = IMDB_DATASET['text']\n",
        "IMDB_DATASET_Y = IMDB_DATASET['label']\n",
        "del IMDB_DATASET\n",
        "\n",
        "\n",
        "# TODO - Start\n",
        "OPENAI_API_KEY = \"REDACTED\"\n",
        "# TODO - End\n",
        "\n",
        "cache = {}\n",
        "def run_gpt3(prompt, return_first_line = True, instruction_tuned = False):\n",
        "    # Return the response from the cache if we have already run this\n",
        "    cache_key = (prompt, return_first_line, instruction_tuned)\n",
        "    if cache_key in cache:\n",
        "        return cache[cache_key]\n",
        "    client = OpenAI(\n",
        "      api_key=OPENAI_API_KEY,\n",
        "    )\n",
        "    # Set the API Key\n",
        "\n",
        "\n",
        "    # Select the model\n",
        "    if instruction_tuned:\n",
        "        model = \"gpt-3.5-turbo-instruct\"\n",
        "    else:\n",
        "        model = \"babbage-002\"\n",
        "\n",
        "    # Send the prompt to GPT-3\n",
        "    for i in range(0,60,6):\n",
        "        try:\n",
        "            response = client.completions.create(\n",
        "                model=model,\n",
        "                prompt=prompt,\n",
        "                temperature=0,\n",
        "                max_tokens=100,\n",
        "                top_p=1,\n",
        "                frequency_penalty=0.0,\n",
        "                presence_penalty=0.0,\n",
        "            )\n",
        "            response = dict(response)['choices'][0]\n",
        "            response = dict(response)['text'].strip()\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            sleep(i)\n",
        "\n",
        "    # Parse the response\n",
        "    if return_first_line:\n",
        "        final_response = response.split('\\n')[0]\n",
        "    else:\n",
        "        final_response = response\n",
        "\n",
        "    # Cache and return the response\n",
        "    cache[cache_key] = final_response\n",
        "    return final_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWjsOg6u6nj5"
      },
      "source": [
        "## Boilerplate Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ1Q_R1t6rHw"
      },
      "outputs": [],
      "source": [
        "def run_unit_test(prompt: str, parameter: str, expected_answer: str, return_first_line=True, instruction_tuned=False):\n",
        "    parameterized_prompt = prompt.replace(\"{input}\", parameter)\n",
        "    answer = run_gpt3(parameterized_prompt, return_first_line, instruction_tuned)\n",
        "\n",
        "    print(\"Expected: \" + expected_answer)\n",
        "    print(\"Actual: \"+ answer)\n",
        "    assert expected_answer in answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGlvLsC9B-gI"
      },
      "source": [
        "# Section 1: Exploring Prompting (12 points)\n",
        "**Background:** Prompting is a way to guide a language model, which is ultimately just a model that predicts the most likely next sequence of words, to complete some arbitrary task you want it to complete. We'll walk through a few examples and then you'll try creating your own prompts.\n",
        "\n",
        "A language model will \"complete\" (just like autocomplete) your prompt with what words are most likely to come next. We demonstrate this is the case by showing how GPT-3 completes movie quotes, when giving it the beginning of the quote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcILHclcou0L",
        "outputId": "deeabf6b-fd1c-4e36-868d-7cc93e2a6fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you never know what you're gonna get. (laughing)\n",
            "comes great responsibility. The same goes for the power of the internet. The internet is a powerful tool, but it can also be a dangerous tool. The internet is a powerful tool, but it can also be a dangerous tool. The internet is a powerful tool, but it can also be a dangerous tool. The internet is a powerful tool, but it can also be a dangerous tool. The internet is a powerful tool, but it can also be a dangerous tool. The internet is a powerful tool\n",
            "James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James Bond. James\n",
            "have a problem.\n",
            "Kansas anymore.\n"
          ]
        }
      ],
      "source": [
        "print(run_gpt3(\"Life is like a box of chocolates,\"))\n",
        "print(run_gpt3(\"With great power,\"))\n",
        "print(run_gpt3(\"The name's Bond.\"))\n",
        "print(run_gpt3(\"Houston, we\"))\n",
        "print(run_gpt3(\"I've a feeling we're not in\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJKLr2kjatM3"
      },
      "source": [
        "Now imagine we give a prompt like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-XKt2tpZzi7",
        "outputId": "982674a1-e367-4038-a15b-dd9e7e58e7b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "George Washington. The first president of the United States was George Washington. He was the first president of the United States. He was the first president of the United States. He was the first president of the United States. He was the first president of the United States. He was the first president of the United States. He was the first president of the United States. He was the first president of the United States. He was the first president of the United States. He was the first president of\n"
          ]
        }
      ],
      "source": [
        "print(run_gpt3(\"Question: Who was the first president of the United States? Answer:\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q41x7bVXbLY-"
      },
      "source": [
        "By posing a question and writing \"Answer:\" at the end, we make it such that the most likely next sequence of words is the answer to the question! This is the key to large language models being able to perform arbitrary tasks, even though they are only trained to predict the next word.\n",
        "\n",
        "We can parameterize this prompt and make it reusable for different questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeHF3-OPZ601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c13378-c4be-4f24-deab-efccf3b901df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple Inc. Steve Jobs founded Apple in 1976. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years.\n",
            "Top Gun.\n",
            "Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a fruit. Tomatoes are a\n"
          ]
        }
      ],
      "source": [
        "QA_PROMPT = \"Question: {input} Answer:\"\n",
        "print(run_gpt3(QA_PROMPT.replace(\"{input}\", \"What company did Steve Jobs found?\")))\n",
        "print(run_gpt3(QA_PROMPT.replace(\"{input}\", \"What's the movie with Tom Cruise about fighter jets?\")))\n",
        "print(run_gpt3(QA_PROMPT.replace(\"{input}\", \"Are tomatoes a fruit or a vegetable?\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWLiOfB_fB-T"
      },
      "source": [
        "Now that you've seen a few examples it's time for you to come up with a few of your own prompts! Make sure you parameterize them with `{input}` and pass in the desired input in your unit tests\n",
        "\n",
        "Note: These models are not easy to control. Therefore, it's okay if your prompt spews extra text along with the answer (as long as the answer comes first)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLPYzcNbJmeb"
      },
      "source": [
        "## Example Unit Test\n",
        "Below will be an example usage of the boilerplate unit test, feel free to use this format in your `report.pdf` but you are free to modify it as you see fit! As you will see, the expected output and actual output is shown in the cell output (required for submission of notebook and `report.pdf`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFhOnDOlJ51N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac76fdc-1792-4e72-fad5-d9fea168db11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: Apple\n",
            "Actual: Apple Inc. Steve Jobs founded Apple in 1976. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years. He was the CEO of Apple for 12 years.\n"
          ]
        }
      ],
      "source": [
        "run_unit_test(QA_PROMPT, \"What company did Steve Jobs found?\", \"Apple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUnnuRJfbXf5"
      },
      "source": [
        "**Please include the prompt, unit tests, and output in your `report.pdf`**\n",
        "\n",
        "**Problem 1.1:** Write a prompt that returns the continent where a country is located."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVUR92UPbSkn"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "CONTINENT_OF_COUNTRY_PROMPT = \"Country: {input} Country's continent:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24kz-a93ds24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc4bb27-a9d8-43ac-bbbc-658435c3194f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: Europe\n",
            "Actual: Europe Continent's country: Romania\n",
            "Expected: Asia\n",
            "Actual: Asia Continent's country: Philippines\n",
            "Expected: Africa\n",
            "Actual: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent: Africa Continent's continent:\n"
          ]
        }
      ],
      "source": [
        "# TODO unit tests\n",
        "run_unit_test(CONTINENT_OF_COUNTRY_PROMPT, \"Romania\", \"Europe\")\n",
        "run_unit_test(CONTINENT_OF_COUNTRY_PROMPT, \"Philippines\", \"Asia\")\n",
        "run_unit_test(CONTINENT_OF_COUNTRY_PROMPT, \"Egypt\", \"Africa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-GAJhyvbido"
      },
      "source": [
        " **Please include the prompt, unit tests, and output in your `report.pdf`**\n",
        "\n",
        " **Problem 1.2:** Write a prompt that returns the author of a famous book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTANEQk9bpa_"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "AUTHOR_OF_BOOK_PROMPT = \"The author of {input} is:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leZQJRM7dvYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab0733c-d91c-4620-b19a-f7bf8523ecc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: L. Frank Baum\n",
            "Actual: L. Frank Baum\n",
            "Expected: George Orwell\n",
            "Actual: George Orwell\n",
            "Expected: John Green\n",
            "Actual: John Green\n"
          ]
        }
      ],
      "source": [
        "# TODO unit tests\n",
        "run_unit_test(AUTHOR_OF_BOOK_PROMPT, \"Wizard of Oz\", \"L. Frank Baum\")\n",
        "run_unit_test(AUTHOR_OF_BOOK_PROMPT, \"1984\", \"George Orwell\")\n",
        "run_unit_test(AUTHOR_OF_BOOK_PROMPT, \"Fault in Our Stars\", \"John Green\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjol744PbwIl"
      },
      "source": [
        " **Please include the prompt, unit tests, and output in your `report.pdf`**\n",
        "\n",
        " **Problem 1.3:** Write a prompt that returns an antonym of a given a word. (Hint: use `return_first_line=False` as an argument when using `run_gpt3`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guWIM6eLb2jA"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "ANTONYMS_OF_WORD_PROMPT = \"Word: {input} Antonym:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwCcFBbMdyic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10d8285-f33d-4819-ab87-5032942588ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: Happy\n",
            "Actual: Happy\n",
            "Expected: small\n",
            "Actual: small\n",
            "Expected: down\n",
            "Actual: down\n"
          ]
        }
      ],
      "source": [
        "# TODO unit tests\n",
        "run_unit_test(ANTONYMS_OF_WORD_PROMPT, \"Sad\", \"Happy\")\n",
        "run_unit_test(ANTONYMS_OF_WORD_PROMPT, \"big\", \"small\")\n",
        "run_unit_test(ANTONYMS_OF_WORD_PROMPT, \"up\", \"down\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cuv5HzCbpzW"
      },
      "source": [
        "**Please include the prompt, unit tests, and output in your `report.pdf`**\n",
        "\n",
        "**Problem 1.4:** Write a prompt that given a molecule (\"water\" or \"hydrogen peroxide\"), returns the atomic elements that make up that molecule. (Hint: use `return_first_line=False` as an argument when using `run_gpt3`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eB3WOnVKbv_R"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "ELEMENT_OF_MOLECULE_PROMPT = \"Molecule: {input} Atomic element:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXlL1J22d1Ro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635e2ccf-4b26-4193-9e0e-ddd5d29fc38e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: K\n",
            "Actual: 19 Symbol: K Atomic mass: 39.098 g/mol Atomic number: 19 Atomic weight: 39.098 g/mol\n",
            "Expected: Br\n",
            "Actual: Br Atomic number: 35 Atomic weight: 79.9 Period: 5 Block: 2, 8, 13, 2, 8, 13, 2, 8, 13, 2, 8, 13, 2, 8, 13, 2, 8, 13, 2, 8, 13, 2, 8, 13, 2, 8, 13,\n",
            "Expected: Au\n",
            "Actual: 79 Symbol: Au Atomic number: 79 Atomic weight: 196.9 Melting point: 1,064.5°C (1,982.1°F) Boiling point: 2,200°C (4,000°F) Density: 19.3 g/cm3 (0.88 lb/in3) Electronegativity: 1.5 (Pauling scale) Electronegativity difference: 0.5 (Pauling scale) Covalent\n"
          ]
        }
      ],
      "source": [
        "# TODO unit tests\n",
        "run_unit_test(ELEMENT_OF_MOLECULE_PROMPT, \"Potassium\", \"K\")\n",
        "run_unit_test(ELEMENT_OF_MOLECULE_PROMPT, \"Bromine\", \"Br\")\n",
        "run_unit_test(ELEMENT_OF_MOLECULE_PROMPT, \"Gold\", \"Au\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "droxlfchrFiK"
      },
      "source": [
        "**Please include the prompt, unit tests, and output in your `report.pdf`**\n",
        "\n",
        "**Problem 1.5:** Write a prompt that given a famous quote (\"One small step for man, one giant leap for mankind.\", quote characters included), returns the name of the person who said the quote (quotee)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZxbEh14rF3e"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "QUOTEE_OF_QUOTE_PROMPT = \"What person said famous quote: {input}? Person:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NOYmf5Ld6Ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73900e0-abd7-49b4-8a54-cce019de2692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: Neil Armstrong\n",
            "Actual: Neil Armstrong Quote 1: \"I am a man of science, but I am also a man of faith.\" Quote 2: \"I am a man of science, but I am also a man of faith.\" Quote 3: \"I am a man of science, but I am also a man of faith.\" Quote 4: \"I am a man of science, but I am also a man of faith.\" Quote 5: \"I am a man of science, but I\n",
            "Expected: Oscar Wilde\n",
            "Actual: Oscar Wilde\n",
            "Expected: Babe Ruth\n",
            "Actual: Babe Ruth quote\n"
          ]
        }
      ],
      "source": [
        "# TODO unit tests\n",
        "run_unit_test(QUOTEE_OF_QUOTE_PROMPT, '\"Thats one small step for man, one giant leap for mankind.\"', 'Neil Armstrong')\n",
        "run_unit_test(QUOTEE_OF_QUOTE_PROMPT, '\"Be yourself; everyone else is already taken\"', 'Oscar Wilde')\n",
        "run_unit_test(QUOTEE_OF_QUOTE_PROMPT, '\"Never let the fear of striking out keep you from playing the game.\"', 'Babe Ruth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVeL7QAhe4Xf"
      },
      "source": [
        "**Please include the prompt, unit tests, and output in your `report.pdf`**\n",
        "\n",
        "**Problem 1.6:** Extend the prompt from 1.5 by completing this one without question marks (\"?\") or question words (\"Who\", \"What\", etc.). You will only get credit if your prompt does not contain those. Hint: Reading, Section 2, may help you with this if you can't figure it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tYTC7wsfSv1"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "EXTENDED_QUOTEE_OF_QUOTE_PROMPT = \"{input} is a famous quote said by:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPM5gLsXfS91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2631edbf-c856-4386-8287-c0dbaf05cb87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: Benjamin Franklin\n",
            "Actual: Benjamin Franklin. Benjamin Franklin was a famous American author, scientist, inventor, statesman, diplomat, and printer. He was a leader of the American Revolution and a Founding Father of the United States. He was a leader of the American Revolution and a Founding Father of the United States. He was a leader of the American Revolution and a Founding Father of the United States. He was a leader of the American Revolution and a Founding Father of the United States. He was a leader of\n",
            "Expected: Albert Einstein\n",
            "Actual: Albert Einstein\n",
            "Expected: Robert Frost\n",
            "Actual: Robert Frost. Robert Frost was an American poet who was born in 1874. He was a very famous poet and he was born in the town of New Hampshire. He was a very famous poet and he was born in the town of New Hampshire. He was a very famous poet and he was born in the town of New Hampshire. He was a very famous poet and he was born in the town of New Hampshire. He was a very famous poet and he was born in the town of New\n",
            "Expected: Descartes\n",
            "Actual: Socrates, Plato, Aristotle, and Descartes. It is a statement that is often used to describe the idea that we are all unique and that we all have our own unique identity. It is a statement that is often used to describe the idea that we are all unique and that we all have our own unique identity. It is a statement that is often used to describe the idea that we are all unique and that we all have our own unique identity. It is a statement that is often\n"
          ]
        }
      ],
      "source": [
        "# TODO unit tests\n",
        "run_unit_test(EXTENDED_QUOTEE_OF_QUOTE_PROMPT, '\"Well done is better than well said.\"', 'Benjamin Franklin')\n",
        "run_unit_test(EXTENDED_QUOTEE_OF_QUOTE_PROMPT, '\"Only a life lived for others is a life worthwhile.\"', 'Albert Einstein')\n",
        "run_unit_test(EXTENDED_QUOTEE_OF_QUOTE_PROMPT, '\"In three words I can sum up everything Ive learned about life: it goes on\"', 'Robert Frost')\n",
        "run_unit_test(EXTENDED_QUOTEE_OF_QUOTE_PROMPT, '\"I think, therefore I am\"', 'Descartes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpJIgznD_mw4"
      },
      "source": [
        "# Section 2: Prompt Engineering (20 points)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "The prompts you have used up to this point have been fairly basic and straightforward to create. But what if you have a more difficult task and it seems like your prompt isn't working? *Prompt engineering* is the procecss of iterating on a prompt in clever ways to induce the model to produce what you want. The best way of prompt engineering systematically vs. randomly is by understanding how the underlying model was trained and what data it was trained on to best prompt the model.\n",
        "\n",
        "Imagine we want the model to generate a quote in Donald Trump's style of talking about a certain topic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwBHGjCc6fdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449c3463-8d0b-47e9-9d01-d3e97b8257a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He would say it’s a “great time to buy.”\n",
            "I don't know what the hell is going on with the stock market. I don't know what's going on with the stock market. I don't know what's going on with the stock market. I don't know what's going on with the stock market. I don't know what's going on with the stock market. I don't know what's going on with the stock market. I don't know what's going on with the stock market. I don't know what's going\n",
            "I think the stock market is going to go up a lot\". The Dow Jones Industrial Average rose 0.5 percent to 24,000. The S&P 500 rose 0.5 percent to 2,600. The Nasdaq Composite Index rose 0.5 percent to 7,100.\n",
            "I don't know if it's going to go up or down\". The Dow Jones Industrial Average fell 0.3 percent to 24,000.54, the S&P 500 lost 0.3 percent to 2,600.97 and the Nasdaq Composite dropped 0.4 percent to 7,075.68.\n"
          ]
        }
      ],
      "source": [
        "DONALD_TRUMP_PROMPT = \"Question: What would Donald Trump say about {input}? Answer:\"\n",
        "DONALD_TRUMP_PROMPT_ENGINEERED_1 = 'On the topic of {input}, Donald Trump was quoted as saying \"'\n",
        "DONALD_TRUMP_PROMPT_ENGINEERED_2 = 'On the topic of {input}, Donald Trump expressed optimism saying \"'\n",
        "DONALD_TRUMP_PROMPT_ENGINEERED_3 = 'On the topic of {input}, Donald Trump expressed doubt saying \"'\n",
        "\n",
        "print(run_gpt3(DONALD_TRUMP_PROMPT.replace(\"{input}\", 'the stock market'))) # Doesn't work\n",
        "print(run_gpt3(DONALD_TRUMP_PROMPT_ENGINEERED_1.replace(\"{input}\", 'the stock market'))) # Works!\n",
        "print(run_gpt3(DONALD_TRUMP_PROMPT_ENGINEERED_2.replace(\"{input}\", 'the stock market'))) # Works!\n",
        "print(run_gpt3(DONALD_TRUMP_PROMPT_ENGINEERED_3.replace(\"{input}\", 'the stock market'))) # Works!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PhkpaGlCVPf"
      },
      "source": [
        "The first naive prompt doesn't really work. After prompt engineering, not only do we get a much more realistic generation of his style, but we can also control whether he is talking about the topic positively or negatively.\n",
        "\n",
        "**Please respond to the following question in your `report.pdf`**\n",
        "\n",
        "* **Problem 2.1:** Why did the `DONALD_TRUMP_PROMPT_ENGINEERED_1` prompt work much better than the `DONALD_TRUMP_PROMPT` prompt? (Word Limit: 100 words)\n",
        "\n",
        " *One - the engineered prompt utilized contextualization in order to output an answer that makes sense. The original prompt simply follows a question-answer format, which opens up possible ambiguity in the output since gpt works better with more straightforward prompts. Two - the way the original prompt is worded seems like it’s asking for a prediction of what Trump would say. It opens with “What would…”, which sounds like it’s not asking for a specific quote of Donald Trump’s, even though that’s the output we want. The engineered prompt saying “...was quoted…” is a better way to ask for a specific quote.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEkQ_gUOTPOT"
      },
      "source": [
        "A prompt that is well-engineered can effectively solve difficult NLP tasks that previously were solved by fine-tuning models. In lecture, we showed some examples of these.\n",
        "\n",
        "**Problem 2.2:** Write a prompt that will solve the [sentiment classification task](https://en.wikipedia.org/wiki/Sentiment_analysis), and classify [movie reviews](https://ai.stanford.edu/~amaas/data/sentiment/) as *positive* or *negative*. `IMDB_DATASET_X` and `IMDB_DATASET_Y` contain 50 reviews and sentiment labels (1 = positive, 0 = negative). Get as high of an accuracy as you can on these. Place your `MOVIE_SENTIMENT` prompt and `POSITIVE_VEBALIZERS` and `NEGATIVE_VERBALIZERS` in `report.pdf` for manual grading. Along with your `correct` (out of 50) score.\n",
        "\n",
        "*Warning:* Be careful not to exhaust your free OpenAI credits while testing, you can check [on this page here](https://platform.openai.com/account/usage). To avoid exhausting your credits quickly, test your code on a few examples from the IMDB dataset first, and then scale up to the full 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FivGbeAmVOK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cfb0372-56be-4b2f-e11d-c44caf33288e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: None, Label: 1\n",
            "Prediction: None, Label: 1\n",
            "Prediction: None, Label: 0\n",
            "Prediction: 0, Label: 1\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: 1, Label: 1\n",
            "Prediction: None, Label: 1\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: None, Label: 1\n",
            "Prediction: None, Label: 1\n",
            "Prediction: None, Label: 0\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: 0, Label: 1\n",
            "Prediction: None, Label: 1\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: None, Label: 0\n",
            "Prediction: None, Label: 1\n",
            "Prediction: None, Label: 1\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: None, Label: 1\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: 0, Label: 1\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: 1, Label: 1\n",
            "Prediction: 0, Label: 1\n",
            "Prediction: 1, Label: 1\n",
            "Prediction: None, Label: 0\n",
            "Prediction: None, Label: 0\n",
            "Prediction: None, Label: 1\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: None, Label: 0\n",
            "Prediction: 0, Label: 1\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: None, Label: 0\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: None, Label: 0\n",
            "Prediction: None, Label: 0\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: None, Label: 0\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: 0, Label: 0\n",
            "Prediction: None, Label: 1\n",
            "Prediction: None, Label: 1\n",
            "Prediction: None, Label: 1\n",
            "Prediction: None, Label: 1\n",
            "Prediction: 0, Label: 0\n",
            "Correct: 21/50\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "MOVIE_SENTIMENT_PROMPT = ''' Classify this IMDB movie review as having either a positive sentiment or negative sentiment.\n",
        "Observe the words in each review.\n",
        "Observe each words sentiment in a sentence.\n",
        "Any review with the word \"awful\" - classify it as negative.\n",
        "ALWAYS CLASSIFY A SENTIMENT TO A MOVIE REVIEW.\n",
        "Given the following IMDB prompt: {input}, this movie review carries the sentiment:'''\n",
        "POSITIVE_VERBALIZERS = [\n",
        "    \"good\",\n",
        "    # TODO - Add other positive verbalizers ...\n",
        "    \"amazing\", \"i love this movie\", \"favorite\", \"hidden gem\", \"I loved it\", \"touching\", \"favorite films\", \"mesmerized\", \"beautiful\", \"beautifully\", \"i loved\", \"fabulous\", \"magnificent\", \"friendship\", \"heartwarming\", \"love\", \"all-time favorite\", \"funniest\", \"adore\", \"brilliant\", \"very funny\", \"creative\" \"favorite\", \"fantastic\", \"great\", \"excited\", \"very funny\", \"excellent\", \"outstanding\", \":)\", \":D\", \"phenomenal\", \"10/10\", \"absolutely loved\", \"must-watch\", \"enjoyed\", \"cute\"\n",
        "]\n",
        "NEGATIVE_VERBALIZERS = [\n",
        "    \"bad\",\n",
        "    # TODO - Add other negative verbalizers ...\n",
        "    \"terrible\", \"awful\", \"horrible\", \":(\", \"seriously?\", \"worst\", \"dislike\", \"not funny\", \"disappointment\", \"i hated\", \"lame\", \"ridiculous\", \"absurd\", \"really stupid\", \"not worth\", \"waste of time\", \"frustrating\", \"shit\", \"implausible\", \"boring\", \"really bad\", \"hate\", \"lazy\", \"dumb\", \"gross\", \"stupid\", \"disappointing\", \"worst\"\n",
        "]\n",
        "\n",
        "def map_to_sentiment_label(gpt3_output):\n",
        "    for v in POSITIVE_VERBALIZERS:\n",
        "        if v.lower() in gpt3_output[:20].lower():\n",
        "            return 1\n",
        "    for v in NEGATIVE_VERBALIZERS:\n",
        "        if v.lower() in gpt3_output[:20].lower():\n",
        "            return 0\n",
        "    return None\n",
        "\n",
        "correct = 0\n",
        "for review, label in zip(IMDB_DATASET_X, IMDB_DATASET_Y):\n",
        "    gpt3_output = run_gpt3(MOVIE_SENTIMENT_PROMPT.replace(\"{input}\", review))\n",
        "    prediction = map_to_sentiment_label(gpt3_output)\n",
        "    if prediction == label:\n",
        "        correct += 1\n",
        "    print(f\"Prediction: {prediction}, Label: {label}\")\n",
        "print(f\"Correct: {correct}/50\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsi2i4y64kvP"
      },
      "source": [
        "# Section 3: Few-Shot Prompting (20 points)\n",
        "\n",
        "The prompts you have seen up until this point are zero-shot prompts, in that we are asking the model to complete a task without any examples. By providing some examples in the prompt, the model becomes significantly more capable. We'll show an example.\n",
        "\n",
        "Consider the task of figuring out a more complex version of a word:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZs-_4-S_vww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4fa596-cde7-4eba-9088-12614e114ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero shot:  Confused. Confused is a word that is used to describe a person who is confused. Confused is a word that is used to describe a person who is confused. Confused is a word that is used to describe a person who is confused. Confused is a word that is used to describe a person who is confused. Confused is a word that is used to describe a person who is confused. Confused is a word that is used to describe a person who is confused. Conf\n",
            "Few shot:  bewildered\n"
          ]
        }
      ],
      "source": [
        "ZERO_SHOT_COMPLEX_PROMPT = \"Question: What is a more complex word for {input}? Answer:\"\n",
        "FEW_SHOT_COMPLEX_PROMPT = \"angry : aggrieved\\nsad : depressed\\n{input} :\"\n",
        "\n",
        "print(\"Zero shot: \", run_gpt3(ZERO_SHOT_COMPLEX_PROMPT.replace(\"{input}\", 'confused'))) # Doesn't work\n",
        "print(\"Few shot: \", run_gpt3(FEW_SHOT_COMPLEX_PROMPT.replace(\"{input}\", 'confused'))) # Works!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yotgY6JWHCRL"
      },
      "source": [
        "The first zero-shot prompt where we have no example doesn't work at all, where as when we give 2 examples in the few-shot prompt (2-shot prompt), it works.\n",
        "\n",
        "Now that you've seen an example of few-shot prompting, it's your turn to try it.\n",
        "\n",
        "**Please include the prompt, unit tests, and output in your `report.pdf`**\n",
        "\n",
        "**Problem 3.1:** Write a few-shot prompt that translates a Spanish word to an English word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEf2PB9WHSus"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "SPANISH_TO_ENGLISH_PROMPT = \"mesa : table\\ncamisa : shirt\\n{input} :\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpIXJVfAeBDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53658c5b-3e14-45ad-a993-4a6ab1665a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: chair\n",
            "Actual: chair\n"
          ]
        }
      ],
      "source": [
        "# TODO unit tests\n",
        "run_unit_test(SPANISH_TO_ENGLISH_PROMPT, \"silla\", \"chair\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afOSMXJ7U-ty"
      },
      "source": [
        "**Please include the prompt, unit tests, and output in your `report.pdf`**\n",
        "\n",
        "**Problem 3.2:** Write a few-shot prompt that converts an input into a [Jeopardy! style answer](https://en.wikipedia.org/wiki/Jeopardy!#:~:text=Rather%20than%20being%20given%20questions,the%20form%20of%20a%20question.) (The Great Lakes -> \"What are the Great Lakes?\" or Taylor Swift -> \"Who is Taylor Swift?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPxTwMR8V92B"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "TO_JEOPARDY_ANSWER_PROMPT = 'City south of Mexico famous for its molé -> \"What is Oaxaca?\"\\nFounder of Facebook/Meta -> \"Who is Mark Zuckerberg?\"\\n{input} ->'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjgD-oogeCmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c3ec66-574d-4639-c562-9202eec4125e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: \"Who is Nicki Minaj?\"\n",
            "Actual: \"Who is Nicki Minaj?\"\n"
          ]
        }
      ],
      "source": [
        "# TODO unit tests\n",
        "run_unit_test(TO_JEOPARDY_ANSWER_PROMPT,'Female rapper who grew up in Queens, New York, famous for her song \"Super Bass\"', '\"Who is Nicki Minaj?\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZykJv03wYrb8"
      },
      "source": [
        "**Please respond to the following question in your `report.pdf`**\n",
        "\n",
        "**Problem 3.3:** Come up with 3 more arbitrary tasks, where a zero-shot prompt might not suffice, and a few-shot prompt would be required. Provide a short write up describing what your tasks are. Provide examples of a zero-prompt not working for it. Then, show us your few-shot prompt and some results. Be creative and try to pick 3 tasks that are somewhat distinct from each other!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Detecting sarcasm\n",
        "\n",
        "This model will identify whether a statement is sarcasm or not."
      ],
      "metadata": {
        "id": "an3MmjEbpSzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SARCASM_ZERO_SHOT_PROMPT = \"{input}; is this sentence sarcastic?\"\n",
        "TOTALLY_NOT_A_FEW_SHOT_PROMPT = '\"I hope youre doing well\" sarcastic? no \\n\"Life is good, you should get one.\" sarcastic? yes\\n\"are you always so stupid or is today a special occasion?\" sarcastic? yes\\n\"You did great, keep it up!\" sarcastic? no\\n{input} sarcastic?'\n",
        "\n",
        "#run_unit_test(SARCASM_ZERO_SHOT_PROMPT, \"Tell me something I don't know.\", \"yes\") <- zero-shot prompt doesn't work.\n",
        "run_unit_test(TOTALLY_NOT_A_FEW_SHOT_PROMPT, \"i don't hold grudges. i remember facts.\", \"yes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKt6KxKtqnm2",
        "outputId": "c0a0540b-954d-4f1d-e773-a310e479cd94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: yes\n",
            "Actual: yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Doofenshmirtz Evil Inc. -inator generator\n",
        "\n",
        "Generates an inator with a given -inator idea"
      ],
      "metadata": {
        "id": "mJxATt2pxg86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INATOR_ZERO_SHOT_PROMPT = \"Dr. Doofensmirtz would build an -inator for {input} and call it the:\"\n",
        "INATOR_FEW_SHOT_PROMPT = \"This -inator was built to pop bubbles: bubble-pop-inator\\n This -inator was built to make every pillow warm: warm-pillow-inator\\n This -inator was built to make everyone bald: bald-inator\\n This -inator was built to {input}:\"\n",
        "\n",
        "#run_unit_test(INATOR_ZERO_SHOT_PROMPT, \"popping bubbles\", \"bubble-pop-inator\") #<- zero-shot prompt doesn't work.\n",
        "run_unit_test(INATOR_FEW_SHOT_PROMPT, \"breaking tables\", \"table-breaker-inator\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UySq450Kx8gf",
        "outputId": "5d994f40-4eeb-415a-ef7f-b2945279189a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: table-breaker-inator\n",
            "Actual: table-breaker-inator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Pokemon types classifier\n",
        "\n",
        "classifies a given pokemon's type(s)"
      ],
      "metadata": {
        "id": "sbQ-ohNPDE_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "POKEMON_TYPE_ZERO_SHOT_PROMPT = \"What type(s) is the Pokémon {input}? Pokémon:\"\n",
        "POKEMON_TYPE_FEW_SHOT_PROMPT = '''Gyrados's Pokémon type is water and flying.\\nClefairy's Pokémon type is fairy.\\n\n",
        "Fenzandipiti's Pokémon type is poison and fairy.\\n\n",
        "Roserade's Pokémon type is grass and poison.\\n\n",
        "Sandile's Pokemon type is grass and poison.\\n\n",
        "Morpeko's Pokémon type is electric and dark.\\n\n",
        "Fennekin's Pokémon type is fire.\\n\n",
        "Psyduck's Pokémon type is water.\\n\n",
        "Klinklang's Pokémon type is steel.\\n\n",
        "Primeape's Pokémon type is fighting.\\n\n",
        "Dragonair's Pokémon type is dragon.\\n\n",
        "Armarouge's Pokémon type is fire and psychic.\\n\n",
        "Araquanid's Pokémon type is water and bug.\\n\n",
        "Gourgeist's Pokémon type is ghost and grass.\\n\n",
        "{input}'s Pokémon type is'''\n",
        "\n",
        "#run_unit_test(POKEMON_TYPE_ZERO_SHOT_PROMPT, 'Snivy', 'grass.') <- zero-shot prompt doesn't work.\n",
        "run_unit_test(POKEMON_TYPE_FEW_SHOT_PROMPT, 'Hoppip', 'flying and grass.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhz3qpWOGjQ8",
        "outputId": "b01dc01e-778b-4d08-c0fc-7c648785022d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: flying and grass.\n",
            "Actual: flying and grass.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfGRGgLCc38j"
      },
      "source": [
        "# Section 4: Prompting Instruction-Tuned Models (18 points)\n",
        "\n",
        "Large language models can be *instruction-tuned*, fine-tuned with examples of instructions and responses to those instructions, to make them easier to prompt and friendlier to humans. Instruction-tuned models can more easily be given natural language instructions describing a task you want them to complete. This makes it so that they are more performant without requiring as much prompt engineering and makes them more likely to succeed with just zero-shot prompting. The version of GPT-3 we were working with in previous exercises was not instruction-tuned, we now will use instruction-tuned models from here on out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HC0Rc41Hdikw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1619a9fb-6b6a-471e-8136-021f97cc690b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's the question that's been on the minds of many a Jeopardy! contestant since the show's debut in 1984. The answer is \"Taylor Swift,\" and the contestant who got it right was a 21-year-old from New York named Ryan. Ryan was the first contestant to correctly answer the question, and he was rewarded with $10,000. Ryan's answer was \"Taylor Swift,\" and he was the first contestant to correctly answer the question, and he was rewarded with\n",
            "\"What is the name of the Grammy-winning singer-songwriter known for hits like 'Shake It Off' and 'Blank Space'?\"\n"
          ]
        }
      ],
      "source": [
        "TO_JEOPARDY_INSTRUCTION_PROMPT = \"What would a Jeopardy! contestant say if the answer was \\\"{input}\\\"?\"\n",
        "\n",
        "print(run_gpt3(TO_JEOPARDY_INSTRUCTION_PROMPT.replace(\"{input}\", 'Taylor Swift'))) # Doesn't work on non-instruction tuned model\n",
        "print(run_gpt3(TO_JEOPARDY_INSTRUCTION_PROMPT.replace(\"{input}\", 'Taylor Swift'), instruction_tuned=True)) # Works and is simpler!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl-njdLbg6Hr"
      },
      "source": [
        "As you can see, these instruction-tuned models make it much simpler to complete complex tasks since you can \"talk\" to them naturally. We'll now ask you to try.\n",
        "\n",
        "**Please include the prompt, unit tests, and output in your `report.pdf`**\n",
        "\n",
        "**Problem 4.1:** Write a prompt that returns the syllables of a word (music -> mu-sic)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoU6zfxps06_"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "WORD_TO_SYLLABLES_PROMPT = \"Break down the following word into its syllables: {input}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CLaWQjFeE1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d0b76b-d8b1-4208-b13e-7342cf6f5564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: cro-co-dile\n",
            "Actual: cro-co-dile\n",
            "Expected: cal-li-graph-y\n",
            "Actual: cal-li-graph-y\n",
            "Expected: i-Phone-8\n",
            "Actual: i-Phone-8\n",
            "Expected: dough\n",
            "Actual: dough\n"
          ]
        }
      ],
      "source": [
        "# TODO unit tests\n",
        "run_unit_test(WORD_TO_SYLLABLES_PROMPT, 'crocodile', 'cro-co-dile', instruction_tuned = True)\n",
        "run_unit_test(WORD_TO_SYLLABLES_PROMPT, 'calligraphy', 'cal-li-graph-y', instruction_tuned = True)\n",
        "run_unit_test(WORD_TO_SYLLABLES_PROMPT, 'iPhone 8', 'i-Phone-8', instruction_tuned = True)\n",
        "run_unit_test(WORD_TO_SYLLABLES_PROMPT, 'dough', 'dough', instruction_tuned = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iBVRD-vfbCf"
      },
      "source": [
        "**Please include the prompt, unit tests, and output in your `report.pdf`**\n",
        "\n",
        "**Problem 4.2:** Modify the word to syllables prompt such that the model only returns the syllables and nothing else. You will only get credit if your model only returns returns the syllables and nothing else."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em04U_nofi5Z"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "MODIFIED_WORD_TO_SYLLABLES_PROMPT = \"Break down the following word into its syllables: {input}. replaces dashes with spaces\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vHGNYVcfjH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2812a4c-b776-4517-c6a3-3904cce5a934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: twen ty\n",
            "Actual: twen ty\n",
            "Expected: mag ne si um\n",
            "Actual: mag ne si um\n",
            "Expected: tor ti lla\n",
            "Actual: tor ti lla\n",
            "Expected: bear\n",
            "Actual: bear\n"
          ]
        }
      ],
      "source": [
        "# TODO unit tests\n",
        "run_unit_test(MODIFIED_WORD_TO_SYLLABLES_PROMPT, 'twenty', 'twen ty', instruction_tuned = True)\n",
        "run_unit_test(MODIFIED_WORD_TO_SYLLABLES_PROMPT, 'magnesium', 'mag ne si um', instruction_tuned = True)\n",
        "run_unit_test(MODIFIED_WORD_TO_SYLLABLES_PROMPT, 'tortilla', 'tor ti lla', instruction_tuned = True)\n",
        "run_unit_test(MODIFIED_WORD_TO_SYLLABLES_PROMPT, 'bear', 'bear', instruction_tuned = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSvhJyZUqNyz"
      },
      "source": [
        "**Please respond to the following question in your `report.pdf`**\n",
        "\n",
        "**Problem 4.3:** Come up with 3 more arbitrary tasks, where the non-instruction-tuned model might not suffice, and an instruction-tuned model would be required. Provide a short write up describing what your tasks are. Provide examples of a prompt not working on a non-instruction-tuned model. Then, show us your instruction prompt on an instruction-tuned model and some results. Be creative and try to pick 3 tasks that are somewhat distinct from each other!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Dinner recommendation\\n Asks what user should have for dinner based on what user has in their pantry/fridge"
      ],
      "metadata": {
        "id": "TAP02kEdqD1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DINNER_ZERO_SHOT_PROMPT = \"Ingredients in fridge/pantry: {input} Dinner recommendation based on ingredients in fridge/pantry:\"\n",
        "DINNER_INSTRUCTION_PROMPT = \"I have {input} in my pantry/fridge. Tell me what I should cook for dinner.\"\n",
        "\n",
        "#run_unit_test(DINNER_ZERO_SHOT_PROMPT, 'chicken, tomato, chicken broth', 'chicken and tomato soup') <- zero-shot prompt doesn't work.\n",
        "run_unit_test(DINNER_INSTRUCTION_PROMPT, 'chicken, tomato, chicken broth', 'chicken and tomato soup', instruction_tuned = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0DcH6f5qWp2",
        "outputId": "02b28022-ec53-44ff-d97c-5a9ff7e71dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: chicken and tomato soup\n",
            "Actual: You could make a delicious chicken and tomato soup! Here's a simple recipe:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Choreography Generator\\n Model suggests a choreography for a given song"
      ],
      "metadata": {
        "id": "SieeFHBlreaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DANCE_ZERO_SHOT_PROMPT = \"If I made a choreography to the song{input}, I would:\"\n",
        "DANCE_INSTRUCTIONS_PROMPT = \"Create a choreography to the song {input}.\"\n",
        "\n",
        "#print(run_gpt3(DANCE_ZERO_SHOT_PROMPT.replace(\"{input}\", 'super bass - nicki minaj'))) <- zero-shot prompt doesn't work.\n",
        "print(run_gpt3(DANCE_INSTRUCTIONS_PROMPT.replace(\"{input}\", 'CHUN LI - nicki minaj'), instruction_tuned=True, return_first_line=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-ocFtjAxqjk",
        "outputId": "a2caab02-5624-49f7-b1cf-ddf2ee35981b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intro:\n",
            "The lights dim as the beat of \"Chun Li\" by Nicki Minaj starts to play. The dancers stand in a line, facing the audience, with their backs straight and arms crossed in front of their chest.\n",
            "\n",
            "Verse 1:\n",
            "As Nicki's first verse begins, the dancers start to move in unison, with sharp and precise movements. They step forward with their right foot, bringing their arms up and crossing them in front of their face. They then step back\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Dream interpretation\\n Model interprets a given short summary of a dream."
      ],
      "metadata": {
        "id": "yXJKUp3U1QA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DREAM_FEW_SHOT_PROMPT = '''Teeth falling out: feelings of inadequacy or vulnerability in your life\\n\n",
        "escaping from tiger: the need to care for yourself, as you may neglect your needs\\n\n",
        "naked in front of a crowd: fear of judgment, concerns about their self-image, or a desire to hide their true self from others\\n\n",
        "''' #source: https://psychcentral.com/health/meaning-of-teeth-falling-out-dream#:~:text=%E2%80%9CThe%20dream%20may%20represent%20feelings,dreams%20about%20teeth%20falling%20out. , https://news.yahoo.com/dreaming-tigers-means-192308988.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAMjVR_ALRzyggiV4FEQd5NeRP54-Wthm0Zd13B4Hs1i1avRpG6GmlXIlWb4IWNETlo1khADzhPbXEeNHM-6xQJWxB9AgIzLN1Ntmjtf6IzaTAsigkhyG-_NB9fztIsFomsEsYu6Gl7GBml3NdRwf6eSPnjJ2HpUXCVlLDkN1KN92#:~:text=Escaping%20from%20a%20tiger%20may,balanced%20for%20a%20healthier%20life.\n",
        "DREAM_INSTRUCTIONS_PROMPT = \"Interpret the deeper meaning of dreaming about {input}.\"\n",
        "\n",
        "#print(run_gpt3(DREAM_FEW_SHOT_PROMPT.replace(\"{input}\", 'my fingers were noodles')))\n",
        "#print(run_gpt3(DREAM_FEW_SHOT_PROMPT.replace(\"{input}\", 'swimming with a shark')))\n",
        "#^^^ both of these few-shot prompts return the same output (fear of being alone: fear of being alone, or the fear of being rejected).\n",
        "print(run_gpt3(DREAM_INSTRUCTIONS_PROMPT.replace(\"{input}\", 'swimming with a shark')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q8aLfO-2uRm",
        "outputId": "36d2cdc6-1458-4832-bbfc-8bb65ad474b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The deeper meaning of dreaming about swimming with a shark is that you are feeling a sense of freedom and excitement. You are feeling that you are in control of your life and you are feeling that you are in control of your destiny. You are feeling that you are in control of your life and you are feeling that you are in control of your destiny. You are feeling that you are in control of your destiny. You are feeling that you are in control of your destiny. You are feeling that you are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVbLbnc3rbbx"
      },
      "source": [
        "# Section 5: Chain-of-Thought Reasoning (30 points)\n",
        "\n",
        "One recent method to prompt large language models is Chain-of-Thought Prompting. This is similar to few-shot prompting, except you not only provide a few examples, but you also provide an explanation with a reasoning chain to the model. Providing this reasoning chain as been shown to improve performance on a wide variety of tasks.\n",
        "\n",
        "We demonstrate on a task that concatenates the last letter of names of length 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HL_emeIHJjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a29661c7-9e3a-4ad8-c2d1-3301265086ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> ry\n",
            "the last letter of 'Stephen' is 'n' and the last letter of 'Curry' is 'y' -> ny\n"
          ]
        }
      ],
      "source": [
        "FEW_SHOT_CONCATENATION_PROMPT = '''\n",
        "Take the last letters of the words 'Alvin Bao' and concatenate them -> no,\n",
        "Take the last letters of the words 'Otto Bot' and concatenate them -> ot,\n",
        "Take the last letters of the words 'Behrang Mohit' and concatenate them -> gt,\n",
        "{input}\n",
        "'''\n",
        "COT_CONCATENATION_PROMPT = '''\n",
        "Take the last letters of the words 'Alvin Bao' and concatenate them\n",
        "the last letter of 'Alvin' is 'n' the last letter of 'Bao' is o -> no,\n",
        "Take the last letters of the words 'Otto Bot' and concatenate them\n",
        "the last letter of 'Otto' is 'o' the last letter of 'Bot' is t -> ot,\n",
        "Take the last letters of the words 'Behrang Mohit' and concatenate them\n",
        "the last letter of 'Behrang' is 'g' and the last letter of 'Mohit' is 't' -> gt,\n",
        "{input}\n",
        "'''\n",
        "\n",
        "print(run_gpt3(FEW_SHOT_CONCATENATION_PROMPT.replace(\"{input}\", \"Take the last letters of the words 'Stephen Curry' and concatenate them\"), instruction_tuned=True)) # Doesn't work without CoT prompting\n",
        "print(run_gpt3(COT_CONCATENATION_PROMPT.replace(\"{input}\", \"Take the last letters of the words 'Stephen Curry' and concatenate them\"), instruction_tuned=True)) # Works!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwy3ToB2wAG9"
      },
      "source": [
        "Next, we create a dataset with 20 examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XtfydODn12U"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Read first name and last name csvs into dataframes\n",
        "first_name_df = pd.read_csv(\"https://raw.githubusercontent.com/Ninble/name-census-top-100/main/first-name-database.csv\", sep=';')\n",
        "last_name_df = pd.read_csv(\"https://raw.githubusercontent.com/Ninble/name-census-top-100/main/surname-database.csv\", sep=';')\n",
        "\n",
        "# Filter only US names\n",
        "first_name_df = first_name_df[first_name_df[\"Country code\"] == \"US\"]\n",
        "last_name_df = last_name_df[last_name_df[\"Country code\"] == \"US\"]\n",
        "\n",
        "# Convert Name column into lists\n",
        "first_names = first_name_df[\"Name\"].tolist()\n",
        "last_names = last_name_df[\"Name\"].tolist()\n",
        "\n",
        "def create_concatenation_dataset(n_examples, seed = 42):\n",
        "    random.seed(seed)\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(n_examples):\n",
        "        first_name = random.choice(first_names)\n",
        "        last_name = random.choice(last_names)\n",
        "        full_name = first_name + \" \" + last_name\n",
        "        X.append(f\"Take the last letters of the words '{full_name}' and concatenate them\")\n",
        "        y.append(first_name[-1] + last_name[-1])\n",
        "    return X, y\n",
        "\n",
        "def parse_answer(model_output):\n",
        "    '''Parses the output of the model to get the final answer.'''\n",
        "    try:\n",
        "        return model_output[-2:]\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "concatenation_X, concatenation_y = create_concatenation_dataset(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHqtOpHp6Vjq"
      },
      "source": [
        "**Please respond to the following question in your `report.pdf`**\n",
        "\n",
        "**Problem 5.1:** Your job is to investigate how few-shot Chain-of-Thought prompting performs vs. regular few-shot prompting over the entire concatenation dataset and grade how many out of 20 are correct. Perform this experiment 5 times each with a different number of regular few-shot examples (1 example, 2 examples, 4 examples, 8 examples, 16 examples) and 5 times again each with a different number of Chain-of-Thought few-shot examples (1 CoT example, 2 CoT examples, 4 CoT examples, 8 CoT examples, 16 CoT examples).\n",
        "\n",
        "Create a table or plot of (N examples) vs. (% questions correct by the model with a few-shot prompt with N examples) vs. (% questions correct by the model with a CoT prompt with N examples). Report this table or plot in `report.pdf` with a short write-up about your observations. Keep the code used to build your table or plot in your notebook for inspection during grading.\n",
        "\n",
        "*Note #1:* Make sure you use `instruction_tuned = True`.\n",
        "\n",
        "*Note #2:* For the purposes of grading, you are **not required** to show the 200 (5 few-shot * 20 examples + 5 COT * 20 examples) examples in the cell output. However, please include the function you wrote to perform this evaluation in `report.pdf`.\n",
        "\n",
        "*Hint:* You might find the `parse_answer` function helpful when grading how many of the model's outputs are correct or not.\n",
        "\n",
        "*Warning:* Be careful not to exhaust your free OpenAI credits while testing, you can check [on this page here](https://platform.openai.com/account/usage). To avoid exhausting your credits quickly, test your code on a smaller concatenation dataset first, and then scale up to the full one to report your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z34fPG7g7yVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d01bc2-9da7-4cb1-a328-eba69e31d39e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([20.0, 20.0, 30.0, 35.0, 45.0], [50.0, 35.0, 100.0, 100.0, 100.0])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# TODO - Solve Problem 5.1 here\n",
        "MY_FEW_SHOT_CONCATENATION_PROMPT = [\n",
        "\"Take the last letters of the words 'Matthew Mojica' and concatenate them -> wa\",\n",
        "\"Take the last letters of the words 'Walter White' and concatenate them -> re\",\n",
        "\"Take the last letters of the words 'Coco Jones' and concatenate them -> os\",\n",
        "\"Take the last letters of the words 'Imani Hakim' and concatenate them -> im\",\n",
        "\"Take the last letters of the words 'Therese Mendoza' and concatenate them -> ea\",\n",
        "\"Take the last letters of the words 'Anthony Duong' and concatenate them -> yg\",\n",
        "\"Take the last letters of the words 'Ken Carson' and concatenate them -> nn\",\n",
        "\"Take the last letters of the words 'James Bay' and concatenate them -> sy\",\n",
        "\"Take the last letters of the words 'Greg Heffley' and concatenate them -> gy\",\n",
        "\"Take the last letters of the words 'Muhammad Ali' and concatenate them -> di\",\n",
        "\"Take the last letters of the words 'Clark Kerr' and concatenate them -> kr\",\n",
        "\"Take the last letters of the words 'Chuck Cheese' and concatenate them -> ke\",\n",
        "\"Take the last letters of the words 'Forrest Gump' and concatenate them -> tp\",\n",
        "\"Take the last letters of the words 'Erin Yaeger' and concatenate them -> nr\",\n",
        "\"Take the last letters of the words 'Donatella Versace' and concatenate them -> ae\",\n",
        "\"Take the last letters of the words 'Rick Owens' and concatenate them -> ks\",\n",
        "\"Take the last letters of the words 'Mike Ehrmantraut' and concatenate them -> et\",\n",
        "\"Take the last letters of the words 'Jessie James' and concatenate them -> es\",\n",
        "\"Take the last letters of the words 'Freddie Mercury' and concatenate them -> ey\",\n",
        "\"Take the last letters of the words 'Jesus Christ' and concatenate them -> st\",\n",
        "\"Take the last letters of the words 'Betty White' and concatenate them -> ye\",\n",
        "\"Take the last letters of the words 'Kanye West' and concatenate them -> et\",\n",
        "\"Take the last letters of the words 'Mac Ayres' and concatenate them -> cs\",\n",
        "\"Take the last letters of the words 'Kate Spade' and concatenate them -> ee\",\n",
        "\"Take the last letters of the words 'Demi Lovato' and concatenate them -> io\",\n",
        "\"Take the last letters of the words 'Wendy Williams' and concatenate them -> ys\",\n",
        "\"Take the last letters of the words 'Stephen Colbert' and concatenate them -> nt\",\n",
        "\"Take the last letters of the words 'Jimmy Fallon' and concatenate them -> yn\",\n",
        "\"Take the last letters of the words 'Ed Sheeran' and concatenate them -> dn\",\n",
        "\"Take the last letters of the words 'Tory Lanez' and concatenate them -> yz\",\n",
        "\"Take the last letters of the words 'Tori Kelly' and concatenate them -> iy\",\n",
        "\"Take the last letters of the words 'Haoyu Chen' and concatenate them -> un\"\n",
        "]\n",
        "\n",
        "MY_COT_CONCATENATION_PROMPT =[\n",
        "\"Take the last letters of the words 'Josh Hug' and concatenate them; the last letter of 'Josh' is 'h' the last letter of 'Hug' is 'g' -> hg\",\n",
        "\"Take the last letters of the words 'Emma Stone' and concatenate them; the last letter of 'Emma' is 'a' the last letter of 'Stone' is 'e' -> ae\",\n",
        "\"Take the last letters of the words 'Ryan Gosling' and concatenate them; the last letter of 'Ryan' is 'n' the last letter of 'Gosling' is 'g' -> ng\",\n",
        "\"Take the last letters of the words 'Maya Angelou' and concatenate them;the last letter of 'Maya' is 'a' the last letter of 'Angelou' is 'u' -> au\",\n",
        "\"Take the last letters of the words 'Coco Chanel' and concatenate them;the last letter of 'Coco' is 'o' the last letter of 'Chanel' is 'l' -> ol\",\n",
        "\"Take the last letters of the words 'Sakura Haruno' and concatenate them;the last letter of 'Sakura' is 'a' the last letter of 'Haruno' is 'o' -> ao\",\n",
        "\"Take the last letters of the words 'Naruto Uzumaki' and concatenate them;the last letter of 'Naruto' is 'o' the last letter of 'Uzumaki' is 'i' -> oi\",\n",
        "\"Take the last letters of the words 'Monkey Luffy' and concatenate them;the last letter of 'Monkey' is 'y' the last letter of 'Luffy' is 'y' -> yy\",\n",
        "\"Take the last letters of the words 'Saskuke Hatake' and concatenate them;the last letter of 'Sasuke' is 'e' the last letter of 'Hatake' is 'e' -> ee\",\n",
        "\"Take the last letters of the words 'Will Smith' and concatenate them;the last letter of 'Will' is 'l' the last letter of 'Smith' is 'h' -> lh\",\n",
        "\"Take the last letters of the words 'Marques Lee' and concatenate them;the last letter of 'Marques' is 's' the last letter of 'Lee' is 'e' -> se\",\n",
        "\"Take the last letters of the words 'Jack Black' and concatenate them;the last letter of 'Jack' is 'k' the last letter of 'Black' is 'k' -> kk\",\n",
        "\"Take the last letters of the words 'George Monkey' and concatenate them;the last letter of 'George' is 'e' the last letter of 'Monkey' is 'y' -> ey\",\n",
        "\"Take the last letters of the words 'Ari Lennox' and concatenate them;the last letter of 'Ari' is 'i' the last letter of 'Lennox' is 'x' -> ix\",\n",
        "\"Take the last letters of the words 'Erykah Badu' and concatenate them;the last letter of 'Erykah' is 'h' the last letter of 'Badu' is 'u' -> hu\",\n",
        "\"Take the last letters of the words 'Pj Morton' and concatenate them;the last letter of 'Pj' is 'j' the last letter of 'Morton' is 'n' -> jn\",\n",
        "\"Take the last letters of the words 'Jill Scott' and concatenate them;the last letter of 'Jill' is 'l' the last letter of 'Scott' is 't' -> lt\",\n",
        "\"Take the last letters of the words 'Lenny Kravitz' and concatenate them;the last letter of 'Lenny' is 'y' the last letter of 'Kravitz' is 'z' -> yz\",\n",
        "\"Take the last letters of the words 'Frank Sinatra' and concatenate them;the last letter of 'Frank' is 'k' the last letter of 'Sinatra' is 'a' -> ka\",\n",
        "\"Take the last letters of the words 'Lebron James' and concatenate them;the last letter of 'Lebron' is 'n' the last letter of 'James' is 's' -> ns\",\n",
        "\"Take the last letters of the words 'Kevin Durant' and concatenate them;the last letter of 'Kevin' is 'n' the last letter of 'Durant' is 't' -> nt\",\n",
        "\"Take the last letters of the words 'Norah Jones' and concatenate them;the last letter of 'Norah' is 'h' the last letter of 'Jones' is 's' -> hs\",\n",
        "\"Take the last letters of the words 'Bridgit Mendler' and concatenate them;the last letter of 'Bridgit' is 't' the last letter of 'Mendler' is 'r' -> tr\",\n",
        "\"Take the last letters of the words 'Snoop Dogg' and concatenate them;the last letter of 'Snoop' is 'p' the last letter of 'Dogg' is 'g' -> pg\",\n",
        "\"Take the last letters of the words 'Robert Frost' and concatenate them;the last letter of 'Robert' is 't' the last letter of 'Frost' is 't' -> tt\",\n",
        "\"Take the last letters of the words 'Jhene Aiko' and concatenate them;the last letter of 'Jhene' is 'e' the last letter of 'Aiko' is 'o' -> eo\",\n",
        "\"Take the last letters of the words 'Vince Staples' and concatenate them;the last letter of 'Vince' is 'e' the last letter of 'Staples' is 's' -> es\",\n",
        "\"Take the last letters of the words 'Jacob Collier' and concatenate them;the last letter of 'Jacob' is 'b' the last letter of 'Collier' is 'r' -> br\",\n",
        "\"Take the last letters of the words 'Jim Carrey' and concatenate them;the last letter of 'Jim' is 'm' the last letter of 'Carrey' is 'y' -> my\",\n",
        "\"Take the last letters of the words 'Max Bemis' and concatenate them;the last letter of 'Max' is 'x' the last letter of 'Bemis' is 's' -> xs\",\n",
        "\"Take the last letters of the words 'Rav Grewal' and concatenate them;the last letter of 'Rav' is 'v' the last letter of 'Grewal' is 'l' -> vl\"\n",
        "]\n",
        "\n",
        "\n",
        "N_examples = [1, 2, 4, 8, 16]\n",
        "few_shot_results = []\n",
        "CoT_results = []\n",
        "\n",
        "for N in N_examples: #5 different trials. -> N_examples list\n",
        "  correct_few_shot = 0\n",
        "  correct_CoT = 0\n",
        "  for i in range(len(concatenation_X)): #the 20 tests. see how many out of 20 are correct given N examples\n",
        "    #create string of examples.\n",
        "    FEW_SHOT_prompt = \"\\n\".join(MY_FEW_SHOT_CONCATENATION_PROMPT[N-1:N-1+N]) + \"\\n{input} ->\"\n",
        "    COT_prompt = \"\\n\".join(MY_COT_CONCATENATION_PROMPT[N-1:N-1+N]) + \"\\n{input} ->\"\n",
        "\n",
        "    #replace {input} with concatenation_X input\n",
        "    FEW_SHOT_prompt_replaced = FEW_SHOT_prompt.replace('{input}', concatenation_X[i])\n",
        "    COT_prompt_replaced = COT_prompt.replace('{input}', concatenation_X[i])\n",
        "\n",
        "    #run thru gpt3\n",
        "    FEW_SHOT_output = run_gpt3(FEW_SHOT_prompt_replaced, instruction_tuned = True)\n",
        "    COT_output = run_gpt3(COT_prompt_replaced, instruction_tuned = True)\n",
        "\n",
        "    #parse answer\n",
        "    FEW_SHOT_final_answer = parse_answer(FEW_SHOT_output)\n",
        "    COT_final_answer = parse_answer(COT_output)\n",
        "\n",
        "\n",
        "    #calculate accuracies\n",
        "    if FEW_SHOT_final_answer == concatenation_y[i]:\n",
        "      correct_few_shot += 1\n",
        "    if COT_final_answer == concatenation_y[i]:\n",
        "      correct_CoT += 1\n",
        "\n",
        "  FEW_SHOT_accuracy = (correct_few_shot / len(concatenation_X)) * 100\n",
        "  few_shot_results.append(FEW_SHOT_accuracy)\n",
        "\n",
        "  COT_accuracy = (correct_CoT / len(concatenation_X)) * 100\n",
        "  CoT_results.append(COT_accuracy)\n",
        "\n",
        "few_shot_results, CoT_results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(N_examples, few_shot_results, label = 'Regular Few-Shot Prompting', marker = 'x');\n",
        "plt.plot(N_examples, CoT_results, label = 'Chain-of-Thought Prompting', marker = 'o');\n",
        "plt.grid(True);\n",
        "plt.legend();\n",
        "plt.xlabel('Number of Examples');\n",
        "plt.ylabel('Accuracy (%)');\n",
        "plt.title('Model Performance on Regular Few-Shot prompting vs. Chain-of-Thought Prompting');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Vg5Gmgric1_R",
        "outputId": "cb6b261b-6eee-44d3-aa8b-0f2fcac384a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report this table or plot in report.pdf with a short write-up about your observations. Keep the code used to build your table or plot in your notebook for inspection during grading.\n",
        "\n",
        "Observations:\n",
        "\n",
        "*   For both prompting methods, accuracy increases when including more examples in the prompt.\n",
        "*   CoT prompting performs exponentially better than few-shot prompting.\n",
        "*   Few-shot gradually increases in accuracy as more examples are fed into gpt-3, while CoT increases quickly with more examples.\n",
        "*   CoT dips in accuracy when going from 1 example to 2 examples (with 2 examples' accuracy being lower than 1 example's accuracy) then quickly increases when using 4 examples. This may be due to the examples I provided in the prompt, but this also shows that not all human-written examples are perfectly processed through gpt-3 even though the examples are written perfectly and that lower example # in a prompt can cause accuracy to also be lower (higher sample sz -> higher accuracy).\n",
        "\n",
        "*   CoT is able to reach 100% accuracy while few-shot cannot (at least with the number of examples we were testing with).\n",
        "\n"
      ],
      "metadata": {
        "id": "tQlEX4JdjK8n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD19h2AQxPgN"
      },
      "source": [
        "**Please respond to the following question in your `report.pdf`**\n",
        "\n",
        "**Problem 5.2 (EXTRA CREDIT):** Your job is to investigate whether or not COT can extend to lengths of words not seen in the chain-of-thought examples.\n",
        "\n",
        "- Step 1: Try running the original concatenation prompt on a name or phrase with 3 words e.g. 'James Earl Jones' (try running it on at least 4-5 names or phrases). Does it work?\n",
        "- Step 2: Go back and modify the prompt to get it to work\n",
        "- Step 3: Now try running this on a name or phrase with 5 words (try running it on at least 4-5 names or phrases). Does it work? If not, how would you extend the prompt to get it to work?\n",
        "\n",
        "Should you decide to do this exploration, in your report, please include what prompts you tried, at least 3 examples of names you tried the prompts on (3 word and 5 word), and an explanation of why you tried what you tried\n",
        "\n",
        "Feel free to reference [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf), especially section 5 on Symbolic Reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2lfoY_Oxa5H"
      },
      "outputs": [],
      "source": [
        "# TODO (EXTRA CREDIT) Modify the following prompt\n",
        "MODIFIED_THREE_WORD_COT_CONCATENATION_PROMPT = ''''''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGtV7hBY-O8s"
      },
      "outputs": [],
      "source": [
        "# TODO unit tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03iZ8waW-NQB"
      },
      "outputs": [],
      "source": [
        "# TODO (EXTRA CREDIT) Modify the following prompt\n",
        "MODIFIED_FIVE_WORD_COT_CONCATENATION_PROMPT = ''''''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGStmZW_-hiA"
      },
      "outputs": [],
      "source": [
        "# TODO unit tests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hoP1RcwMqNF"
      },
      "source": [
        "# Submissions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DfjnoJXNfCZ"
      },
      "source": [
        "## Submission Checklist (check if you missed anything!)\n",
        "We will look for the following:\n",
        "- Section 1:\n",
        "  - 1.1: Prompt, 3 unit tests, and output included in `report.pdf` and notebook\n",
        "  - 1.2: Prompt, 3 unit tests, and output included in `report.pdf` and notebook\n",
        "  - 1.3: Prompt, 3 unit tests, and output included in `report.pdf` and notebook\n",
        "  - 1.4: Prompt, 3 unit tests, and output included in `report.pdf` and notebook\n",
        "  - 1.5: Prompt, 3 unit tests, and output included in `report.pdf` and notebook\n",
        "  - 1.6: Prompt, 3 unit tests, and output included in `report.pdf` and notebook\n",
        "- Section 2:\n",
        "  - 2.1: Written response in `report.pdf` (Word Limit: 100 words)\n",
        "  - 2.2: Written response in `report.pdf` and verification of prompt, verbalizers, and number correct\n",
        "- Section 3:\n",
        "  - 3.1: Prompt, 3 unit tests, and output included in `report.pdf` and notebook\n",
        "  - 3.2: Prompt, 3 unit tests, and output included in `report.pdf` and notebook\n",
        "  - 3.3: Written response in `report.pdf`\n",
        "- Section 4:\n",
        "  - 4.1: Prompt, 3 unit tests, and output included in `report.pdf` and notebook\n",
        "  - 4.2: Prompt, 3 unit tests, and output included in `report.pdf` and notebook\n",
        "  - 4.3: Written response in `report.pdf`\n",
        "- Section 5:\n",
        "  - 5.1: Written response (table/plot, short-write up) in `report.pdf` and verification of prompt and evaluation function (examples from cell output not required)\n",
        "  - 5.2: **OPTIONAL**: Written response in `report.pdf` and verification of 2 prompts and 6 unit tests\n",
        "\n",
        "For the purpose of submission, feel free to complete the entire assignment in the notebook and then convert it into a pdf for the report. However, this is not required as long as all of the deliverables above are satisfied.\n",
        "\n",
        "**REMINDER**: Include the **expected** answer and the **response** from the OpenAI API in the cell output and `report.pdf` **for all unit tests**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx1oLs9-OFjE"
      },
      "source": [
        "## GradeScope File Submission\n",
        "\n",
        "**MAKE SURE TO REMOVE YOUR API KEY FROM YOUR SUBMISSION, YOU WILL LOSE POINTS IF YOUR API KEY IS PRESENT IN THE NOTEBOOK SUBMISSION**\n",
        "\n",
        "Here are the deliverables you need to submit to GradeScope:\n",
        "- Write-up (`report.pdf`):\n",
        "    - All Sections\n",
        "    - **IMPORTANT**: You will be assigning each page of the report to a question so please make sure you have the correct page(s) assigned to each question, **you will lose 10 points on this assignment if your answers are not assigned correctly**.\n",
        "- Code:\n",
        "    - This notebook: make sure it is named `HW4.ipynb` before submitting. You can download the notebook and py file by going to the top-left corner of this webpage, `File -> Download -> Download .ipynb`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}