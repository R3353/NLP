{"cells":[{"cell_type":"code","metadata":{"source_hash":"37bd41be","execution_start":1714326383148,"execution_millis":26488,"deepnote_to_be_reexecuted":false,"cell_id":"c6f1cc585a294deda2be476cb98cd6e2","deepnote_cell_type":"code"},"source":"!pip install transformers\n!pip install nltk\n!pip install spacy\n!python -m spacy download en_core_web_sm","block_group":"321a64d4fc28422780833f1d639b92f7","execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /root/venv/lib/python3.9/site-packages (4.40.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /root/venv/lib/python3.9/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from transformers) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from transformers) (2022.9.13)\nRequirement already satisfied: numpy>=1.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from transformers) (1.23.4)\nRequirement already satisfied: filelock in /shared-libs/python3.9/py/lib/python3.9/site-packages (from transformers) (3.8.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /root/venv/lib/python3.9/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /root/venv/lib/python3.9/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: requests in /shared-libs/python3.9/py/lib/python3.9/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /root/venv/lib/python3.9/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.4.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests->transformers) (3.4)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: nltk in /shared-libs/python3.9/py/lib/python3.9/site-packages (3.7)\nRequirement already satisfied: joblib in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (1.2.0)\nRequirement already satisfied: click in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (8.1.3)\nRequirement already satisfied: tqdm in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (4.64.1)\nRequirement already satisfied: regex>=2021.8.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (2022.9.13)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: spacy in /shared-libs/python3.9/py/lib/python3.9/site-packages (3.4.2)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (0.10.1)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (2.4.5)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (0.4.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (3.3.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (1.0.9)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (1.0.3)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (2.28.1)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from spacy) (21.3)\nRequirement already satisfied: numpy>=1.15.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (1.23.4)\nRequirement already satisfied: pathy>=0.3.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (0.6.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (4.64.1)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (3.0.8)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from spacy) (58.1.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (3.0.10)\nRequirement already satisfied: jinja2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: thinc<8.2.0,>=8.1.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (8.1.5)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (1.10.2)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.9)\nRequirement already satisfied: smart-open<6.0.0,>=5.2.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\nRequirement already satisfied: typing-extensions>=4.1.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from jinja2->spacy) (2.0.0)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n2024-04-28 17:46:39.611296: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-04-28 17:46:39.882866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2024-04-28 17:46:39.882913: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2024-04-28 17:46:39.923213: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-04-28 17:46:41.218513: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2024-04-28 17:46:41.218722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2024-04-28 17:46:41.218761: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n2024-04-28 17:46:42.930743: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2024-04-28 17:46:42.930795: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2024-04-28 17:46:42.930831: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-3b6f8c22-749e-426f-b9e2-c8df176f9f68): /proc/driver/nvidia/version does not exist\nCollecting en-core-web-sm==3.4.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from en-core-web-sm==3.4.1) (3.4.2)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.4.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\nRequirement already satisfied: thinc<8.2.0,>=8.1.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\nRequirement already satisfied: pathy>=0.3.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.6.2)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (58.1.0)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.28.1)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\nRequirement already satisfied: jinja2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.1.2)\nRequirement already satisfied: numpy>=1.15.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.23.4)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\nRequirement already satisfied: smart-open<6.0.0,>=5.2.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\nRequirement already satisfied: typing-extensions>=4.1.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.4.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.4)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.0)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/340c109b-6032-4fd9-b4fb-bc4ed38163ca","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326203701,"execution_millis":6118,"deepnote_to_be_reexecuted":false,"cell_id":"bc340b1fa92d48aaba528ff5a799a9ea","deepnote_cell_type":"code"},"source":"from scipy import sparse\nfrom sklearn import linear_model\nfrom collections import Counter\nimport operator\nimport nltk\nimport math\nfrom scipy.stats import norm\nfrom transformers import BertModel, BertTokenizer\nimport torch\nimport torch.nn as nn\nimport random\nimport spacy\nfrom nltk.corpus import wordnet\nfrom nltk.tag import pos_tag","block_group":"196b66bdf9b94d73ba6b2eb2b28d08e0","execution_count":null,"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n2024-04-28 17:43:27.048877: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-04-28 17:43:27.243732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2024-04-28 17:43:27.243759: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2024-04-28 17:43:27.275801: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-04-28 17:43:28.209079: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2024-04-28 17:43:28.209179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2024-04-28 17:43:28.209191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n2024-04-28 17:43:29.251664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2024-04-28 17:43:29.251713: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2024-04-28 17:43:29.251740: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-3b6f8c22-749e-426f-b9e2-c8df176f9f68): /proc/driver/nvidia/version does not exist\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/5fb778da-4280-4b2a-8bf2-179452cc7b0f","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326209846,"execution_millis":52,"deepnote_to_be_reexecuted":false,"cell_id":"321a64d4fc28422780833f1d639b92f7","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np \nfrom IPython.display import display\nimport os","block_group":"8641a3296a194c0f9060b282f9c64c42","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326209847,"execution_millis":2175,"deepnote_to_be_reexecuted":false,"cell_id":"56dc996a33b24cfdaf6184d338c084c3","deepnote_cell_type":"code"},"source":"!python -m nltk.downloader punkt","block_group":"36c89deb2bbd4364a787d5d2da25fecf","execution_count":null,"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/466dd63a-e644-47a8-9341-f2e02cdf1e6b","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326212032,"execution_millis":204,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":10,"pageIndex":32},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"cell_id":"b6d3a07776694df6913c6175e8740a31","deepnote_cell_type":"code"},"source":"adjudications = pd.read_csv(\"adjudications.csv\") # has 544 data points\nadjudications = adjudications.sample(frac=1, random_state=11).drop(columns=['data point ID', 'adjudicated'])\ntraining = adjudications[:327] # training with 327 rows has around 60% of the 544 data points\ndevelopment = adjudications[327:436] # development with 109 rows has around 20% of the 544 data points\ntest = adjudications[436:544] # test with 108 rows has around 20% of the 544 data points\ntraining","block_group":"6b3a26a8c537414fb6ff1548a9caf06a","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":2,"row_count":327,"columns":[{"name":"label","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"witty","count":168},{"name":"lame","count":93},{"name":"funny","count":66}]}},{"name":"text","dtype":"object","stats":{"unique_count":327,"nan_count":0,"categories":[{"name":"We’re renovating the house, and the first floor is going great, but the second floor is another story.","count":1},{"name":"Why do peppers make such good archers? Because they habanero.","count":1},{"name":"325 others","count":325}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"label":"lame","text":"I was sitting on the back porch with my wife when I suddenly blurted out, \"I love you.\" \"Is that you or the beer talking?\" she asked. I answered, \"It's me... talking to my beer.\"","_deepnote_index_column":325},{"label":"witty","text":"I thought about going on an all-almond diet. But that's just nuts.","_deepnote_index_column":256},{"label":"witty","text":"Do you know how many people are dead at a cemetery? All of them.","_deepnote_index_column":479},{"label":"funny","text":"My mother in law bought a talking parrot, but returned it a week later. \"This parrot hasn't spoke a single word.\" She complained.\"I haven't had a fucking chance to!\" Replied the parrot.","_deepnote_index_column":384},{"label":"lame","text":"Denmark: \"We will kill 17 million minks by 2021.\" China: \"I killed 20 million in two weeks.\"World: \"You killed 20 million minks in 2 weeks??\"China: \"Oh no, sorry, I must've misheard you.\"","_deepnote_index_column":478},{"label":"witty","text":"Where do you learn all about ice cream? Sundae school.","_deepnote_index_column":289},{"label":"funny","text":"A sandwich walks into a bar. The barman says: 'sorry we don't serve food here'","_deepnote_index_column":394}]},"text/plain":"     label                                               text\n369  witty  We’re renovating the house, and the first floo...\n372  funny  Why do peppers make such good archers? Because...\n175  funny  My wife gave me an ultimatum: Her or my addict...\n538   lame  What did the ravioli play on his birthday? Pas...\n347   lame  If Trump wanted to avoid impeachment... ...he ...\n..     ...                                                ...\n479  witty  Do you know how many people are dead at a ceme...\n384  funny  My mother in law bought a talking parrot, but ...\n478   lame  Denmark: \"We will kill 17 million minks by 202...\n289  witty  Where do you learn all about ice cream? Sundae...\n394  funny  A sandwich walks into a bar. The barman says: ...\n\n[327 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>369</th>\n      <td>witty</td>\n      <td>We’re renovating the house, and the first floo...</td>\n    </tr>\n    <tr>\n      <th>372</th>\n      <td>funny</td>\n      <td>Why do peppers make such good archers? Because...</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>funny</td>\n      <td>My wife gave me an ultimatum: Her or my addict...</td>\n    </tr>\n    <tr>\n      <th>538</th>\n      <td>lame</td>\n      <td>What did the ravioli play on his birthday? Pas...</td>\n    </tr>\n    <tr>\n      <th>347</th>\n      <td>lame</td>\n      <td>If Trump wanted to avoid impeachment... ...he ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>witty</td>\n      <td>Do you know how many people are dead at a ceme...</td>\n    </tr>\n    <tr>\n      <th>384</th>\n      <td>funny</td>\n      <td>My mother in law bought a talking parrot, but ...</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>lame</td>\n      <td>Denmark: \"We will kill 17 million minks by 202...</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>witty</td>\n      <td>Where do you learn all about ice cream? Sundae...</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>funny</td>\n      <td>A sandwich walks into a bar. The barman says: ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>327 rows × 2 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/a917b326-0ea9-44cd-a29e-c81ea8c9d39f","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326212180,"execution_millis":1248,"deepnote_to_be_reexecuted":false,"cell_id":"d695d3d37c0942f383ce3c32a2f45242","deepnote_cell_type":"code"},"source":"# make txt files \ntraining.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\nos.rename(\"train.tsv\", \"train.txt\")\n\ndevelopment.to_csv(\"dev.tsv\", sep=\"\\t\", index=False)\nos.rename(\"dev.tsv\", \"dev.txt\")\n\ntest.to_csv(\"test.tsv\", sep=\"\\t\", index=False)\nos.rename(\"test.tsv\", \"test.txt\")","block_group":"fc39b519d40c48a4b5f1962516ac29d3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326213432,"execution_millis":283,"deepnote_to_be_reexecuted":false,"cell_id":"e38a8d207ebc45b5902dad99d88da297","deepnote_cell_type":"code"},"source":"training","block_group":"205d5434a57940b9860f6d577d180c6c","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":2,"row_count":327,"columns":[{"name":"label","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"witty","count":168},{"name":"lame","count":93},{"name":"funny","count":66}]}},{"name":"text","dtype":"object","stats":{"unique_count":327,"nan_count":0,"categories":[{"name":"We’re renovating the house, and the first floor is going great, but the second floor is another story.","count":1},{"name":"Why do peppers make such good archers? Because they habanero.","count":1},{"name":"325 others","count":325}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"label":"witty","text":"We’re renovating the house, and the first floor is going great, but the second floor is another story.","_deepnote_index_column":369},{"label":"funny","text":"Why do peppers make such good archers? Because they habanero.","_deepnote_index_column":372},{"label":"funny","text":"My wife gave me an ultimatum: Her or my addiction to sweets. The decision was a piece of cake.","_deepnote_index_column":175},{"label":"lame","text":"What did the ravioli play on his birthday? Pasta Parcel.","_deepnote_index_column":538},{"label":"lame","text":"If Trump wanted to avoid impeachment... ...he should’ve falsely claimed there were WMDs in Iraq","_deepnote_index_column":347},{"label":"lame","text":"I find it hard to talk openly about the holes in my hands and feet Just feels likes there’s a lot of stigmata attached","_deepnote_index_column":179},{"label":"witty","text":"Why is it so cheap to throw a party at a haunted house? Because the ghosts bring all the boos.","_deepnote_index_column":83},{"label":"witty","text":"My wife told me that I twist everything she says to my advantage. I take that as a compliment.","_deepnote_index_column":473},{"label":"funny","text":"I asked my dog what's two minus two. He said nothing.","_deepnote_index_column":129},{"label":"witty","text":"Two strings walk into a bar... ...the bartender says, \"What'll it be?\". The first string says, \"I'll have a gin and tonic#MV*()>SDk+\u001e!^\u001c \u0002\u0012&\u0006@P&\u001d]JEA&#65535;Segmentation Fault\".The second string says, \"You'll have to excuse my friend, he's not null-terminated.\"","_deepnote_index_column":436}]},"text/plain":"     label                                               text\n369  witty  We’re renovating the house, and the first floo...\n372  funny  Why do peppers make such good archers? Because...\n175  funny  My wife gave me an ultimatum: Her or my addict...\n538   lame  What did the ravioli play on his birthday? Pas...\n347   lame  If Trump wanted to avoid impeachment... ...he ...\n..     ...                                                ...\n479  witty  Do you know how many people are dead at a ceme...\n384  funny  My mother in law bought a talking parrot, but ...\n478   lame  Denmark: \"We will kill 17 million minks by 202...\n289  witty  Where do you learn all about ice cream? Sundae...\n394  funny  A sandwich walks into a bar. The barman says: ...\n\n[327 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>369</th>\n      <td>witty</td>\n      <td>We’re renovating the house, and the first floo...</td>\n    </tr>\n    <tr>\n      <th>372</th>\n      <td>funny</td>\n      <td>Why do peppers make such good archers? Because...</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>funny</td>\n      <td>My wife gave me an ultimatum: Her or my addict...</td>\n    </tr>\n    <tr>\n      <th>538</th>\n      <td>lame</td>\n      <td>What did the ravioli play on his birthday? Pas...</td>\n    </tr>\n    <tr>\n      <th>347</th>\n      <td>lame</td>\n      <td>If Trump wanted to avoid impeachment... ...he ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>witty</td>\n      <td>Do you know how many people are dead at a ceme...</td>\n    </tr>\n    <tr>\n      <th>384</th>\n      <td>funny</td>\n      <td>My mother in law bought a talking parrot, but ...</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>lame</td>\n      <td>Denmark: \"We will kill 17 million minks by 202...</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>witty</td>\n      <td>Where do you learn all about ice cream? Sundae...</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>funny</td>\n      <td>A sandwich walks into a bar. The barman says: ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>327 rows × 2 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/d360adca-c404-49e4-ba8b-48b40d6a967f","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326213461,"execution_millis":407,"deepnote_to_be_reexecuted":false,"cell_id":"a1cae72fa05d4938ba911cae7e64b060","deepnote_cell_type":"code"},"source":"trainX = training['text']\ntrainY = training['label']\ndevX = development['text']\ndevY = development['label']\ntestX = test['text']\ntestY = test['label']","block_group":"684284df8da84063845bbb6f41fa385d","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"8abfbd44654c4c3a9146c99c3e531124","deepnote_cell_type":"text-cell-h1"},"source":"# LOGISTIC REGRESSION","block_group":"464b528f67b04d6c82e1ae7d17bae13e"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326213478,"execution_millis":391,"deepnote_to_be_reexecuted":false,"cell_id":"b86a9a10f48b499c9c7befd0737ab332","deepnote_cell_type":"code"},"source":"#Logistic Regression \n\nclass Classifier:\n\n    def __init__(self, feature_method, trainX, trainY, devX, devY, testX, testY):\n        self.feature_vocab = {}\n        self.feature_method = feature_method\n        self.min_feature_count=2\n        self.log_reg = None\n\n        self.trainY=trainY\n        self.devY=devY\n        self.testY=testY\n        \n        self.trainX = self.process(trainX, training=True)\n        self.devX = self.process(devX, training=False)\n        self.testX = self.process(testX, training=False)\n\n    # Featurize entire dataset\n    def featurize(self, data):\n        featurized_data = []\n        for text in data:\n            feats = self.feature_method(text)\n            featurized_data.append(feats)\n        return featurized_data\n\n    # Read dataset and returned featurized representation as sparse matrix + label array\n    def process(self, X_data, training = False):\n        \n        data = self.featurize(X_data)\n\n        if training:\n            fid = 0\n            feature_doc_count = Counter()\n            for feats in data:\n                for feat in feats:\n                    feature_doc_count[feat]+= 1\n\n            for feat in feature_doc_count:\n                if feature_doc_count[feat] >= self.min_feature_count:\n                    self.feature_vocab[feat] = fid\n                    fid += 1\n\n        F = len(self.feature_vocab)\n        D = len(data)\n        X = sparse.dok_matrix((D, F))\n        for idx, feats in enumerate(data):\n            for feat in feats:\n                if feat in self.feature_vocab:\n                    X[idx, self.feature_vocab[feat]] = feats[feat]\n\n        return X\n\n\n    # Train model and evaluate on held-out data\n    def train(self):\n        (D,F) = self.trainX.shape\n        best_dev_accuracy=0\n        best_model=None\n        for C in [0.1, 1, 10, 100]:\n            self.log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n            self.log_reg.fit(self.trainX, self.trainY)\n            training_accuracy = self.log_reg.score(self.trainX, self.trainY)\n            development_accuracy = self.log_reg.score(self.devX, self.devY)\n            if development_accuracy > best_dev_accuracy:\n                best_dev_accuracy=development_accuracy\n                best_model=self.log_reg\n\n#             print(\"C: %s, Train accuracy: %.3f, Dev accuracy: %.3f\" % (C, training_accuracy, development_accuracy))\n\n        self.log_reg=best_model\n        \n\n    def test(self):\n        return self.log_reg.score(self.testX, self.testY)\n        \n\n    def printWeights(self, n=10):\n\n        reverse_vocab=[None]*len(self.log_reg.coef_[0])\n        for k in self.feature_vocab:\n            reverse_vocab[self.feature_vocab[k]]=k\n\n        # binary\n        if len(self.log_reg.classes_) == 2:\n              weights=self.log_reg.coef_[0]\n\n              cat=self.log_reg.classes_[1]\n              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n              print()\n\n              cat=self.log_reg.classes_[0]\n              for feature, weight in list(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1)))[:n]:\n                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n              print()\n\n        # multiclass\n        else:\n          for i, cat in enumerate(self.log_reg.classes_):\n\n              weights=self.log_reg.coef_[i]\n\n              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n              print()","block_group":"276a38c5946e486faae49eab8594575a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326213503,"execution_millis":366,"deepnote_to_be_reexecuted":false,"cell_id":"5ec376f6acdc46afa21620cbc54b14f6","deepnote_cell_type":"code"},"source":"def binary_bow_featurize(text):\n    feats = {}\n    words = nltk.word_tokenize(text)\n\n    for word in words:\n        word=word.lower()\n        feats[word]=1\n            \n    return feats","block_group":"b5743ee8d0ec464d8175e2c41593c93c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326213510,"execution_millis":360,"deepnote_to_be_reexecuted":false,"cell_id":"c916dfa148dc4962b90ec66a309cb79f","deepnote_cell_type":"code"},"source":"def confidence_intervals(accuracy, n, significance_level):\n    critical_value=(1-significance_level)/2\n    z_alpha=-1*norm.ppf(critical_value)\n    se=math.sqrt((accuracy*(1-accuracy))/n)\n    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)","block_group":"b7ab62b767734442b1e4981425d38fab","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326213548,"execution_millis":685,"deepnote_to_be_reexecuted":false,"cell_id":"4fd6821cbfb548c1ac68756ab512c402","deepnote_cell_type":"code"},"source":"simple_classifier = Classifier(binary_bow_featurize, trainX, trainY, devX, devY, testX, testY)\nsimple_classifier.train()\naccuracy=simple_classifier.test()\naccuracy","block_group":"2ba5d7717d834df388babaca49574beb","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"0.5"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/62b9f5ee-2346-40c6-94fd-465de1f79316","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d4aa7ccdd91b44c2a2636295a9e48499","deepnote_cell_type":"text-cell-h1"},"source":"# MAJORITY CLASS CLASSIFIER","block_group":"6b06bd04c8304420ab87ef2e1721083f"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326214236,"execution_millis":61,"deepnote_to_be_reexecuted":false,"cell_id":"63ee146bc3f24e99afd022be7581cded","deepnote_cell_type":"code"},"source":"#Majority Class Classifier\ndef majority_class(trainY, evalY):\n    labelCounts=Counter()\n    for label in trainY:\n        labelCounts[label]+=1\n    majority_class=labelCounts.most_common(1)[0][0]\n    \n    correct=0.\n    for label in evalY:\n        if label == majority_class:\n            correct+=1\n    return majority_class, correct/len(evalY)\n\nmc, mc_devAcc=majority_class(trainY, devY)\n\n\nprint(\"Majority class: %s, dev accuracy: %.3f\" % (mc, mc_devAcc))","block_group":"a2a233ada575442ebdc4b7b0a86be26f","execution_count":null,"outputs":[{"name":"stdout","text":"Majority class: witty, dev accuracy: 0.743\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/c6fc5f8b-3417-4721-823e-86d86bd01c67","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7fc1d83524714dcc9c62776029521d31","deepnote_cell_type":"text-cell-h1"},"source":"# FEATURIZATIONS!!!!","block_group":"fd34d120de72414fabd7fa720de39f62"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326214268,"execution_millis":262,"deepnote_to_be_reexecuted":false,"cell_id":"8c8dd1bd8bfb4b1a80876f9749f35e0c","deepnote_cell_type":"code"},"source":"nltk.download('wordnet')\nnltk.download('omw-1.4')","block_group":"0cf2a8b34f074310925a36534e5e9cb8","execution_count":null,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /root/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"True"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/aa9115e5-844c-4fa1-8dc8-9d8b71649634","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326214533,"execution_millis":79,"deepnote_to_be_reexecuted":false,"cell_id":"e1c9d5916b1d480c9bf2aa04bdd95788","deepnote_cell_type":"code"},"source":"# featurizations\n\ndef multiple_meanings(text): \n    '''\n    one possible feature for pun detection.\n    this function looks for multiple meanings in the words in a given text.\n    '''\n\n    features = {}\n    tokens = nltk.word_tokenize(text)\n\n    for token in tokens:\n      token = token.lower()\n      synsets = wordnet.synsets(token)\n      if token not in features.keys():\n          features[token] = len(synsets)\n\n    return features\n    \ndef culture_references(text): \n    '''\n    a possible feature to detect whether a joke makes general and/or pop culture references.\n    primarily utilizes named entity recognition (NER).\n    '''\n    nlp = spacy.load(\"en_core_web_sm\")\n    doc = nlp(text)\n    named_entities = [ent.text for ent in doc.ents]\n\n    features = {}\n    tokens = nltk.word_tokenize(text) \n\n    for token in tokens:\n        if token in named_entities:\n            features[token] = 1\n        else:\n            features[token] = 0\n\n    return features \n\ndef expected_pos(text): # food for thought\n    # detects whether a word in a text is the expected part of speech\n    # if not, this may be indicative of the word's purpose as a pun \n    tokens = word_tokenize(text)\n    pos_tags = pos_tag(tokens)\n\ndef word_count(text):\n    '''\n    classifies as 'witty' or not-'witty' based on word count.\n    Based on EDA, we find that the avg word count for 'witty' label is ~14.7, while 'funny' is ~18.9 and 'lame' is ~19.8.\n    Utilize BoW kinda not rly\n    '''\n    witty_count = 14.7\n    funny_count = 18.9\n    lame_count = 19.8\n\n    witty_class\n\n    features = {}\n    tokens = nltk.word_tokenize(text) \n\n    features[tokens] = len(tokens)\n\ndef lame_list(text):\n    '''\n    classifies as 'lame' if topic of joke contains a word from a list of words\n    Utilizes BoW\n    '''\n    lame_topics = ['onlyfans', 'trump', 'dick', 'nut', 'corona', 'covid', 'covid-19', 'date', 'depresso', 'sex'] \n\n    features = {}\n    tokens = nltk.word_tokenize(text) \n\n    for word in words:\n        word.lower()\n        if word in lame_topics:\n            features[tokens] = 1\n        else:\n            features[token] = 0    ","block_group":"921ae509533b41d3a254a15a2855e26b","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326214563,"execution_millis":49,"deepnote_to_be_reexecuted":false,"cell_id":"e70186fa906f4739a3f0412e4fef4dd9","deepnote_cell_type":"code"},"source":"# consolidate all features into one function to feed into our classifier later \ndef combined_features(text):\n    all_features={}\n    for feature in [multiple_meanings, culture_references, word_count, lame_list]:\n        all_features.update(feature(text))\n    return all_features","block_group":"f9f1a2ab57bf4700b6d7b0c0f972eb71","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"6316077c07ee4faf94d967f00b5595a3","deepnote_cell_type":"text-cell-h1"},"source":"# Classifier with features","block_group":"9223e3c4cb5b431199d3bd9d2104594f"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326271391,"execution_millis":465,"deepnote_to_be_reexecuted":false,"cell_id":"e1b48342cc6349c58b6278371b6b3a16","deepnote_cell_type":"code"},"source":"#This function takes in an array of texts, and for each text, finds the number of \n#words that have multiple meanings \n\ndef count_multiple_meanings(texts):\n    meanings_count = np.array([])\n    for text in texts:\n        meanings = list(multiple_meanings(text).values())\n        meanings_count = np.append(meanings_count, sum([word > 1 for word in meanings]))\n    return meanings_count\n\ntrain_meanings = count_multiple_meanings(trainX)\ndev_meanings = count_multiple_meanings(devX)\ntest_meanings = count_multiple_meanings(testX)","block_group":"9a07fe67626947d4b52a4d0c32b67b02","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326289529,"execution_millis":89,"deepnote_to_be_reexecuted":false,"cell_id":"b66ca655bda04e4a9a1dc1f25d2b8c97","deepnote_cell_type":"code"},"source":"def count_references(texts):\n    reference_count = np.array([])\n    for text in texts:\n        references = list(culture_references(text).values())\n        reference_count = np.append(reference_count, sum(references))\n    return reference_count\n\n#count_references(trainX)","block_group":"9f9f0556f17049b3ab4aebb8a10a7525","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"669c35cc7b924384930942d5c5bbf0c3","deepnote_cell_type":"text-cell-h1"},"source":"# BERT","block_group":"68235d1113c04c15968a649a26fc9b6f"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326303929,"execution_millis":158,"deepnote_to_be_reexecuted":false,"cell_id":"c432d7c662644f278f2dc2cd5037bd10","deepnote_cell_type":"code"},"source":"# now let's try running our features through a BERT classifier\n# see https://github.com/ucbnlp24/hws4nlp24/blob/main/AP/BERT.ipynb for inspo ","block_group":"2279875597474a11a2e774e0fced75f3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326304935,"execution_millis":241,"deepnote_to_be_reexecuted":false,"cell_id":"a5034f7848d04a329fad62f2abb9cfa6","deepnote_cell_type":"code"},"source":"# trainX = training['text']\n# trainY = training['label']\n# devX = development['text']\n# devY = development['label']\n# testX = test['text']\n# testY = test['label']\n\ntrainX.tolist()\ntrainY.tolist()\n\n#trainX, trainY, devX, devY, testX, testYtrainX, trainY, devX, devY, testX, testY","block_group":"5fea4b516a3e440ead9dfbc87f0316a0","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"['witty',\n 'funny',\n 'funny',\n 'lame',\n 'lame',\n 'lame',\n 'witty',\n 'witty',\n 'funny',\n 'witty',\n 'lame',\n 'lame',\n 'witty',\n 'witty',\n 'lame',\n 'funny',\n 'lame',\n 'lame',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'funny',\n 'witty',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'funny',\n 'witty',\n 'funny',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'lame',\n 'lame',\n 'funny',\n 'lame',\n 'witty',\n 'funny',\n 'lame',\n 'lame',\n 'witty',\n 'lame',\n 'funny',\n 'lame',\n 'lame',\n 'witty',\n 'lame',\n 'lame',\n 'lame',\n 'witty',\n 'witty',\n 'lame',\n 'lame',\n 'witty',\n 'funny',\n 'funny',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'funny',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'witty',\n 'funny',\n 'witty',\n 'funny',\n 'witty',\n 'lame',\n 'funny',\n 'witty',\n 'lame',\n 'funny',\n 'funny',\n 'witty',\n 'lame',\n 'funny',\n 'funny',\n 'lame',\n 'witty',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'lame',\n 'lame',\n 'funny',\n 'witty',\n 'lame',\n 'lame',\n 'witty',\n 'funny',\n 'funny',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'funny',\n 'witty',\n 'funny',\n 'funny',\n 'witty',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'witty',\n 'lame',\n 'funny',\n 'witty',\n 'funny',\n 'funny',\n 'lame',\n 'lame',\n 'witty',\n 'lame',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'lame',\n 'lame',\n 'lame',\n 'lame',\n 'witty',\n 'funny',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'lame',\n 'lame',\n 'funny',\n 'lame',\n 'lame',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'lame',\n 'witty',\n 'lame',\n 'lame',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'lame',\n 'funny',\n 'lame',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'lame',\n 'lame',\n 'funny',\n 'funny',\n 'lame',\n 'funny',\n 'lame',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'funny',\n 'witty',\n 'lame',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'funny',\n 'lame',\n 'funny',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'lame',\n 'witty',\n 'funny',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'funny',\n 'funny',\n 'funny',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'lame',\n 'lame',\n 'funny',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'funny',\n 'witty',\n 'witty',\n 'witty',\n 'lame',\n 'witty',\n 'witty',\n 'funny',\n 'lame',\n 'witty',\n 'funny']"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/b155d231-28f4-4d1f-acba-08329c06f171","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326305671,"execution_millis":121,"deepnote_to_be_reexecuted":false,"cell_id":"84a26d642db146ee825a3027a98be834","deepnote_cell_type":"code"},"source":"def read_labels(col):\n    labels={}\n    for elem in col: \n        if elem not in labels:\n            labels[elem] = len(labels)\n    return labels","block_group":"f9902a20a7b74ea2a7a74e36b98420c5","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326307181,"execution_millis":128,"deepnote_to_be_reexecuted":false,"cell_id":"b286ce136eb84392997b2d2921112855","deepnote_cell_type":"code"},"source":"def read_data(x, y, labels, max_data_points=1000):\n  \n    data = []\n    data_labels = []\n\n    for text, label in zip(x, y):\n        data.append(text)\n        data_labels.append(labels[label])\n            \n\n    # shuffle the data\n    tmp = list(zip(data, data_labels))\n    random.shuffle(tmp)\n    data, data_labels = zip(*tmp)\n    \n    if max_data_points is None:\n        return data, data_labels\n    \n    return data[:max_data_points], data_labels[:max_data_points]","block_group":"698d85808b564c6891bf1c00b76328aa","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326308329,"execution_millis":79,"deepnote_to_be_reexecuted":false,"cell_id":"68ebdcc91c534fa494272eb1b0d0e557","deepnote_cell_type":"code"},"source":"labels = read_labels(trainY)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","block_group":"87ec75ab7c744ad5b83b8588f25e8e41","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326309323,"execution_millis":80,"deepnote_to_be_reexecuted":false,"cell_id":"e66cc5c4843840fc91286d41d9451514","deepnote_cell_type":"code"},"source":"train_x, train_y=read_data(trainX, trainY, labels, max_data_points=None)\ndev_x, dev_y=read_data(devX, devY, labels, max_data_points=None)\ntest_x, test_y=read_data(testX, testY, labels, max_data_points=None)","block_group":"bb20573a431141ba93ef87b483364f01","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"e5d714c6","execution_start":1714326425828,"execution_millis":61,"deepnote_to_be_reexecuted":false,"cell_id":"bf2086d231f4490b89163ec31baf76f1","deepnote_cell_type":"code"},"source":"class BERTClassifier(nn.Module):\n\n    def __init__(self, bert_model_name, params):\n        super().__init__()\n    \n        self.model_name=bert_model_name\n        self.tokenizer = BertTokenizer.from_pretrained(self.model_name, do_lower_case=params[\"doLowerCase\"], do_basic_tokenize=False)\n        self.bert = BertModel.from_pretrained(self.model_name)\n        \n        self.num_labels = params[\"label_length\"]\n\n        self.fc = nn.Linear(params[\"embedding_size\"], self.num_labels)\n\n    def get_batches(self, all_x, all_y, batch_size=16, max_toks=510):\n            \n        \"\"\" Get batches for input x, y data, with data tokenized according to the BERT tokenizer \n      (and limited to a maximum number of WordPiece tokens \"\"\"\n\n        batches_x=[]\n        batches_y=[]\n        \n        for i in range(0, len(all_x), batch_size):\n\n            current_batch=[]\n\n            x=all_x[i:i+batch_size]\n\n            batch_x = self.tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_toks)\n            batch_y=all_y[i:i+batch_size]\n\n            batches_x.append(batch_x.to(device))\n            batches_y.append(torch.LongTensor(batch_y).to(device))\n            \n        return batches_x, batches_y\n  \n\n    def forward(self, batch_x): \n    \n        bert_output = self.bert(input_ids=batch_x[\"input_ids\"],\n                         attention_mask=batch_x[\"attention_mask\"],\n                         token_type_ids=batch_x[\"token_type_ids\"],\n                         output_hidden_states=True)\n\n      # We're going to represent an entire document just by its [CLS] embedding (at position 0)\n      # And use the *last* layer output (layer -1)\n      # as a result of this choice, this embedding will be optimized for this purpose during the training process.\n      \n        bert_hidden_states = bert_output['hidden_states']\n\n        out = bert_hidden_states[-1][:,0,:]\n\n        out = self.fc(out)\n\n        return out.squeeze()","block_group":"552b03d73da94e94b7dd67e87cf8aefb","execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'nn' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBERTClassifier\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, bert_model_name, params):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}],"outputs_reference":"dbtable:cell_outputs/bea52459-4b5f-4824-9f22-b660867798f0","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326310858,"execution_millis":86,"deepnote_to_be_reexecuted":false,"cell_id":"0cf60864250f46daa5f655ca5e82a4fb","deepnote_cell_type":"code"},"source":"def train(bert_model_name, model_filename, train_x, train_y, dev_x, dev_y, labels, embedding_size=768, doLowerCase=None):\n\n    bert_model = BERTClassifier(bert_model_name, params={\"label_length\": len(labels), \"doLowerCase\":doLowerCase, \"embedding_size\":embedding_size})\n    bert_model.to(device)\n\n    batch_x, batch_y = bert_model.get_batches(train_x, train_y)\n    dev_batch_x, dev_batch_y = bert_model.get_batches(dev_x, dev_y)\n\n    optimizer = torch.optim.Adam(bert_model.parameters(), lr=1e-5)\n    cross_entropy=nn.CrossEntropyLoss()\n\n    num_epochs=30\n    best_dev_acc = 0.\n    patience=5\n\n    best_epoch=0\n\n    for epoch in range(num_epochs):\n        bert_model.train()\n\n        # Train\n        for x, y in zip(batch_x, batch_y):\n            y_pred = bert_model.forward(x)\n            loss = cross_entropy(y_pred.view(-1, bert_model.num_labels), y.view(-1))\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        # Evaluate\n        dev_accuracy, _=evaluate(bert_model, dev_batch_x, dev_batch_y)\n        if epoch % 1 == 0:\n            print(\"Epoch %s, dev accuracy: %.3f\" % (epoch, dev_accuracy))\n            if dev_accuracy > best_dev_acc:\n                torch.save(bert_model.state_dict(), model_filename)\n                best_dev_acc = dev_accuracy\n                best_epoch=epoch\n        if epoch - best_epoch > patience:\n            print(\"No improvement in dev accuracy over %s epochs; stopping training\" % patience)\n            break\n\n    bert_model.load_state_dict(torch.load(model_filename))\n    print(\"\\nBest Performing Model achieves dev accuracy of : %.3f\" % (best_dev_acc))\n    return bert_model","block_group":"ac236d991af146a0822593f493a4b618","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326311548,"execution_millis":100,"deepnote_to_be_reexecuted":false,"cell_id":"df071b9604934aa89d08b463efab56e2","deepnote_cell_type":"code"},"source":"def confidence_intervals(accuracy, n, significance_level):\n    critical_value=(1-significance_level)/2\n    z_alpha=-1*norm.ppf(critical_value)\n    se=math.sqrt((accuracy*(1-accuracy))/n)\n    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)","block_group":"fa7897713db14a99a9e90b79af5edae8","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714326312358,"execution_millis":0,"deepnote_to_be_reexecuted":false,"cell_id":"494ec7fc65e541cc8cf2ce7ce8ebf1bc","deepnote_cell_type":"code"},"source":"# train bert model \nbert_model_name=\"bert-base-cased\"\nmodel_filename=\"mybert.model\"\nembedding_size=768\ndoLowerCase=False\n\nmodel=train(bert_model_name, model_filename, train_x, train_y, dev_x, dev_y, labels, embedding_size=embedding_size, doLowerCase=doLowerCase)","block_group":"12f5fd0965554780805d4ee4f7b40308","execution_count":null,"outputs":[{"output_type":"error","ename":"KernelInterrupted","evalue":"Execution interrupted by the Jupyter kernel.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."]}],"outputs_reference":"dbtable:cell_outputs/0183bcff-1dd8-44b3-bbb9-0e5bbe26f0d9","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"f1c07450052647238ce9607dce129966","deepnote_cell_type":"code"},"source":"test_batch_x, test_batch_y = model.get_batches(test_x, test_y)\naccuracy, test_n=evaluate(model, test_batch_x, test_batch_y)\n\nlower, upper=confidence_intervals(accuracy, test_n, .95)\nprint(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))","block_group":"b0a5c74d71cb4c9894f21d650716a491","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714319284724,"execution_millis":143,"deepnote_to_be_reexecuted":true,"cell_id":"80f68b9de009435db775d5f2fb871b30","deepnote_cell_type":"code"},"source":"nltk.download('averaged_perceptron_tagger')\nnltk.download('universal_tagset')","block_group":"4bca1c266e6b4f27a9702bf1d244f4e1","execution_count":null,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /root/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n[nltk_data]   Unzipping taggers/universal_tagset.zip.\n","output_type":"stream"},{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"True"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/02a18a98-89b7-4d6f-8f97-a71d4baeb13a","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714319285587,"execution_millis":105,"deepnote_to_be_reexecuted":true,"cell_id":"301b95d4c64c4a14b09d1129998efa71","deepnote_cell_type":"code"},"source":"text = \"I want to go on record that I support farming. As a matter of fact, you could call me protractor.\"\ntokens = nltk.word_tokenize(text)\npos_tags = pos_tag(tokens, tagset='universal')\npos_tags\n\n\n#IM LOSING IT","block_group":"bffe3d45155f40c68f4fca5c037c6e35","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"[('I', 'PRON'),\n ('want', 'VERB'),\n ('to', 'PRT'),\n ('go', 'VERB'),\n ('on', 'ADP'),\n ('record', 'NOUN'),\n ('that', 'ADP'),\n ('I', 'PRON'),\n ('support', 'VERB'),\n ('farming', 'VERB'),\n ('.', '.'),\n ('As', 'ADP'),\n ('a', 'DET'),\n ('matter', 'NOUN'),\n ('of', 'ADP'),\n ('fact', 'NOUN'),\n (',', '.'),\n ('you', 'PRON'),\n ('could', 'VERB'),\n ('call', 'VERB'),\n ('me', 'PRON'),\n ('protractor', 'NOUN'),\n ('.', '.')]"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/5f5899d2-c7e9-4af8-b2f0-29f010830d3e","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"69b3da3eb9f8454fb4a0a11996bff4c9","deepnote_cell_type":"code"},"source":"","block_group":"9fee660e0ccd4e3f9d47405fe643e1d7","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"12f0eef4aaf54dd884202489fe795be5","deepnote_cell_type":"code"},"source":"","block_group":"e632b660f2d34eb2857666b698b36c87","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3b6f8c22-749e-426f-b9e2-c8df176f9f68' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"4ae25536631448aeab4ff980ca9314fb","deepnote_execution_queue":[]}}